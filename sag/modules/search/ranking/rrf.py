"""
æœç´¢ RRF æ¨¡å—

å®ç°ä» keys ç›´æ¥æŸ¥æ‰¾å…³è”äº‹é¡¹çš„åŠŸèƒ½ï¼Œä½¿ç”¨ä¸‰é˜¶æ®µç­–ç•¥ï¼ˆBM25+RRFç»‘å®šæ‰§è¡Œï¼‰ï¼š
1. Embedding ç›¸ä¼¼åº¦é˜ˆå€¼è¿‡æ»¤ï¼ˆç²—æ’ï¼‰ï¼šä½¿ç”¨é¢„å­˜å‘é‡è®¡ç®—ä¸queryçš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œè¿‡æ»¤ä½ç›¸å…³äº‹é¡¹
2. BM25 é‡æ’åºï¼ˆç²¾æ’ï¼‰ï¼šå¯¹é€šè¿‡é˜ˆå€¼çš„äº‹é¡¹ä½¿ç”¨ BM25 ç®—æ³•è¿›è¡Œå…³é”®è¯åŒ¹é…æ’åº
3. RRF èåˆï¼ˆè‡ªåŠ¨ï¼‰ï¼šä½¿ç”¨ Reciprocal Rank Fusion èåˆ Embedding å’Œ BM25 ä¸¤ç§æ’åºç»“æœ

å¤„ç†æµç¨‹ï¼ˆä¼˜åŒ–ç‰ˆ - ç›´æ¥ä½¿ç”¨ key_idï¼‰ï¼š
1. ç›´æ¥ä½¿ç”¨ key_idï¼škey_final ä¸­çš„ key_id å°±æ˜¯ Entity è¡¨çš„ idï¼Œæ— éœ€æŸ¥è¯¢ Entity è¡¨
2. äº‹ä»¶å…³è”ï¼šé€šè¿‡ EventEntity è¡¨æ‰¾åˆ°ä¸è¿™äº›å®ä½“ç›¸å…³çš„äº‹ä»¶
3. äº‹é¡¹å»é‡ï¼šåŸºäºäº‹é¡¹IDå»é‡ï¼Œé˜²æ­¢åŒä¸€ä¸ªäº‹é¡¹å¤šæ¬¡è¿”å›
4. å‘é‡ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆç²—æ’ï¼‰ï¼šä» ES æ‰¹é‡è·å–äº‹é¡¹å‘é‡ï¼Œè®¡ç®—ä¸ query çš„åŠ æƒä½™å¼¦ç›¸ä¼¼åº¦
5. é˜ˆå€¼è¿‡æ»¤ï¼šè¿‡æ»¤æ‰ç›¸ä¼¼åº¦ä½äºé˜ˆå€¼çš„äº‹é¡¹
6. BM25 è®¡ç®—ï¼šå¯¹é€šè¿‡é˜ˆå€¼çš„äº‹é¡¹ä½¿ç”¨ BM25 ç®—æ³•è®¡ç®—åˆ†æ•°ï¼ˆä½¿ç”¨ fast_mode è·³è¿‡ spaCyï¼Œåªç”¨ jieba åˆ†è¯ï¼‰
7. RRF èåˆï¼šèåˆ Embedding æ’åºå’Œ BM25 æ’åºï¼Œè®¡ç®— RRF åˆ†æ•°
8. Top-N é™åˆ¶ï¼šè¿”å›å‰ N ä¸ªäº‹é¡¹

RRF èåˆç®—æ³•ï¼š
RRF_score(d) = Î£ 1/(k + rank_i(d))
åœ¨æˆ‘ä»¬çš„åœºæ™¯ä¸­ï¼š
RRF_score(event) = 1/(k + embedding_rank) + 1/(k + bm25_rank)
å…¶ä¸­ k å›ºå®šä¸º 60ï¼Œç”¨äºå¹³è¡¡ä¸åŒæ’åºç³»ç»Ÿçš„å½±å“

é…ç½®å‚æ•°ï¼š
- config.query: æŸ¥è¯¢æ–‡æœ¬
- config.query_embedding: æŸ¥è¯¢å‘é‡ï¼ˆç¼“å­˜ï¼‰
- config.source_config_id: æ•°æ®æºID
- config.rerank.score_threshold: Embedding ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆé»˜è®¤0.5ï¼‰
- config.rerank.max_results: è¿”å›äº‹é¡¹æ•°é‡ï¼ˆé»˜è®¤8ï¼‰

è¿”å›æ ¼å¼ï¼š
Dict[str, Any]: åŒ…å«ä»¥ä¸‹å­—æ®µçš„å­—å…¸ï¼š
    - events (List[SourceEvent]): äº‹é¡¹å¯¹è±¡åˆ—è¡¨ï¼Œæ¯ä¸ªå¯¹è±¡é™„åŠ å±æ€§:
        - similarity_score (float): Embedding ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆç²—æ’åˆ†æ•°ï¼‰
        - embedding_rank (int): Embedding æ’åï¼ˆRRF ä½¿ç”¨ï¼‰
        - bm25_score (float): BM25 åˆ†æ•°ï¼ˆç²¾æ’åˆ†æ•°ï¼‰
        - bm25_rank (int): BM25 æ’åï¼ˆRRF ä½¿ç”¨ï¼‰
        - rrf_score (float): RRF èåˆåˆ†æ•°ï¼ˆæœ€ç»ˆæ’åºä¾æ®ï¼‰
        - clues (List[Dict]): å¬å›è¯¥äº‹é¡¹çš„å®ä½“çº¿ç´¢åˆ—è¡¨ï¼ˆæ¥è‡ª key_finalï¼‰
    - clues (Dict): å¬å›çº¿ç´¢ä¿¡æ¯
        - origin_query (str): åŸå§‹æŸ¥è¯¢ï¼ˆé‡å†™å‰ï¼‰
        - final_query (str): LLMé‡å†™åçš„æŸ¥è¯¢ï¼ˆé‡å†™åï¼‰
        - query_entities (List[Dict]): æŸ¥è¯¢å¬å›çš„å®ä½“åˆ—è¡¨ï¼ˆkey_idæ”¹ä¸ºidï¼‰
        - recall_entities (List[Dict]): å¬å›çš„å®ä½“åˆ—è¡¨ï¼ˆkey_idæ”¹ä¸ºidï¼Œè¿‡æ»¤æ‰query_entitiesä¸­çš„å€¼ï¼‰
"""

from typing import Any, Dict, List, Tuple
import time
import numpy as np

from sqlalchemy import select, and_
from sqlalchemy.orm import selectinload

from sag.core.storage.elasticsearch import get_es_client
from sag.core.storage.repositories.event_repository import EventVectorRepository
from sag.core.ai.tokensize import get_mixed_tokenizer
from sag.db import SourceEvent, EventEntity, SourceConfig, Article, get_session_factory
from sag.modules.search.config import SearchConfig
from sag.modules.search.tracker import Tracker  # ğŸ†• æ·»åŠ çº¿ç´¢è¿½è¸ªå™¨
from sag.utils import get_logger

logger = get_logger("search.rerank.rrf")


class RerankRRFSearcher:
    """RRFæœç´¢å™¨ - ä»keysç›´æ¥æŸ¥æ‰¾å…³è”äº‹é¡¹ï¼ˆä¸¤é˜¶æ®µæ’åºï¼‰"""

    def __init__(self, llm_client=None):
        """
        åˆå§‹åŒ–RRFæœç´¢å™¨

        Args:
            llm_client: LLMå®¢æˆ·ç«¯ï¼ˆå¯é€‰ï¼Œæš‚æœªä½¿ç”¨ï¼‰
        """
        self.session_factory = get_session_factory()
        self.logger = get_logger("search.rerank.rrf")

        # åˆå§‹åŒ–Elasticsearchä»“åº“
        self.es_client = get_es_client()
        self.event_repo = EventVectorRepository(self.es_client)

        self.logger.info("RRFæœç´¢å™¨åˆå§‹åŒ–å®Œæˆ")

    async def search(
        self,
        key_final: List[Dict[str, Any]],
        config: SearchConfig
    ) -> Dict[str, Any]:
        """
        ä» keys ç›´æ¥æŸ¥æ‰¾å…³è”äº‹é¡¹ï¼ˆEmbeddingç²—æ’ + BM25ç²¾æ’ + RRFèåˆï¼‰

        å¤„ç†æµç¨‹ï¼š
        1. å®ä½“åŒ¹é…ï¼šæ ¹æ® key_final ä¸­çš„å®ä½“åç§°å’Œç±»å‹ï¼Œåœ¨ Entity è¡¨ä¸­æŸ¥æ‰¾åŒ¹é…çš„å®ä½“
        2. äº‹ä»¶å…³è”ï¼šé€šè¿‡ EventEntity è¡¨æ‰¾åˆ°ä¸è¿™äº›å®ä½“ç›¸å…³çš„äº‹ä»¶
        3. äº‹é¡¹å»é‡ï¼šåŸºäºäº‹é¡¹IDå»é‡ï¼Œé˜²æ­¢åŒä¸€ä¸ªäº‹é¡¹å¤šæ¬¡è¿”å›
        4. Embedding ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆç²—æ’ï¼‰ï¼šä» ES æ‰¹é‡è·å–äº‹é¡¹å‘é‡ï¼Œè®¡ç®—ä¸ query çš„ä½™å¼¦ç›¸ä¼¼åº¦
        5. é˜ˆå€¼è¿‡æ»¤ï¼šè¿‡æ»¤æ‰ç›¸ä¼¼åº¦ä½äºé˜ˆå€¼çš„äº‹é¡¹
        6. BM25 + RRF èåˆæ’åºï¼ˆç²¾æ’ï¼‰ï¼šä½¿ç”¨ BM25 å’Œ RRF ç®—æ³•èåˆ Embedding å’Œå…³é”®è¯ä¸¤ç§æ’åº
        7. Top-K é™åˆ¶ï¼šè¿”å›å‰ K ä¸ªäº‹é¡¹

        é…ç½®å‚æ•°ï¼š
        - config.query: æŸ¥è¯¢æ–‡æœ¬
        - config.query_embedding: æŸ¥è¯¢å‘é‡ï¼ˆç¼“å­˜ï¼‰
        - config.source_config_id: æ•°æ®æºID
        - config.rerank.score_threshold: Embedding ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆé»˜è®¤0.5ï¼‰
        - config.rerank.max_results: è¿”å›äº‹é¡¹æ•°é‡ï¼ˆé»˜è®¤8ï¼‰

        æ³¨æ„ï¼š
        - BM25 å’Œ RRF èåˆç»‘å®šï¼Œæ— éœ€å•ç‹¬é…ç½®
        - RRF å¸¸æ•° k å›ºå®šä¸º 60

        Args:
            key_final: ä»Recallæˆ–Expandè¿”å›çš„å…³é”®å®ä½“åˆ—è¡¨
            config: æœç´¢é…ç½®å¯¹è±¡

        Returns:
            Dict[str, Any]: åŒ…å«ä»¥ä¸‹å­—æ®µçš„å­—å…¸ï¼š
                - events (List[SourceEvent]): äº‹é¡¹å¯¹è±¡åˆ—è¡¨ï¼ˆæŒ‰RRFåˆ†æ•°æ’åºï¼Œæœ€å¤šè¿”å›top_kä¸ªï¼‰ï¼Œæ¯ä¸ªå¯¹è±¡é™„åŠ å±æ€§:
                    - similarity_score (float): Embedding ä½™å¼¦ç›¸ä¼¼åº¦
                    - embedding_rank (int): Embedding æ’å
                    - bm25_score (float): BM25 åˆ†æ•°
                    - bm25_rank (int): BM25 æ’å
                    - rrf_score (float): RRF èåˆåˆ†æ•°ï¼ˆæœ€ç»ˆæ’åºä¾æ®ï¼‰
                - clues (Dict): å¬å›çº¿ç´¢ä¿¡æ¯
                    - origin_query (str): åŸå§‹æŸ¥è¯¢ï¼ˆé‡å†™å‰ï¼‰
                    - final_query (str): LLMé‡å†™åçš„æŸ¥è¯¢ï¼ˆé‡å†™åï¼‰
                    - query_entities (List[Dict]): æŸ¥è¯¢å¬å›çš„å®ä½“åˆ—è¡¨ï¼ˆkey_idæ”¹ä¸ºidï¼‰
                    - recall_entities (List[Dict]): å¬å›çš„å®ä½“åˆ—è¡¨ï¼ˆkey_idæ”¹ä¸ºidï¼Œè¿‡æ»¤æ‰query_entitiesä¸­çš„å€¼ï¼‰
        """
        try:
            # ä» config ä¸­æå–å‚æ•°
            query = config.query
            query_vector = config.query_embedding
            source_config_ids = config.get_source_config_ids()  # ğŸ†• æ”¯æŒå¤šä¿¡æ¯æº
            threshold = config.rerank.score_threshold  # ä½¿ç”¨é€šç”¨é˜ˆå€¼å‚æ•°
            top_k = config.rerank.max_results  # ä½¿ç”¨é€šç”¨ top_k å‚æ•°
            rrf_k = 60  # RRF å¸¸æ•°å›ºå®šä¸º 60

            self.logger.info(
                f"RRFæœç´¢å¼€å§‹: å¤„ç† {len(key_final)} ä¸ªkeys, "
                f"query='{query}', source_config_ids={source_config_ids}, threshold={threshold}, top_k={top_k}"
            )

            if not key_final:
                # åˆ¤æ–­æ˜¯å¦åº”è¯¥è¿”å› final_query
                # å¦‚æœå¯ç”¨äº†queryé‡å†™åŠŸèƒ½ï¼ˆenable_query_rewrite=Trueï¼‰ï¼Œåˆ™è¿”å›é‡å†™åçš„query
                # å¦åˆ™è¿”å› None
                final_query = config.query if config.enable_query_rewrite else None
                return {
                    "events": [],
                    "clues": {
                        "origin_query": config.original_query,
                        "final_query": final_query,
                        "query_entities": [],
                        "recall_entities": []
                    }
                }

            # æ­¥éª¤1-3: å®ä½“åŒ¹é… â†’ äº‹ä»¶å…³è” â†’ å»é‡
            events, event_to_clues = await self._get_events_from_keys(key_final, source_config_ids)
            if not events:
                self.logger.warning(
                    f"âš ï¸ RRFæ­¥éª¤1-3å¤±è´¥ï¼šæœªä» {len(key_final)} ä¸ªå®ä½“æ‰¾åˆ°ä»»ä½•å…³è”äº‹é¡¹ã€‚"
                    f"å¯èƒ½åŸå› ï¼š1) EventEntityè¡¨æ— æ•°æ®å…³è” 2) source_config_ids {source_config_ids} æ— åŒ¹é…äº‹é¡¹"
                )
                self.logger.warning(
                    f"å®ä½“åˆ—è¡¨ï¼š{[k['name'] for k in key_final[:5]]}")
                return self._build_response(config, key_final, [], {})

            self.logger.info(f"âœ… æ­¥éª¤1-3: ä»å®ä½“æŸ¥æ‰¾åˆ° {len(events)} ä¸ªå…³è”äº‹é¡¹")

            # æ­¥éª¤4: Embedding ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆç²—æ’ï¼‰
            events_with_scores = await self._calculate_embedding_similarity(
                events, query_vector
            )
            if not events_with_scores:
                self.logger.warning(
                    f"âš ï¸ RRFæ­¥éª¤4å¤±è´¥ï¼šEmbeddingç›¸ä¼¼åº¦è®¡ç®—è¿”å›ç©ºç»“æœã€‚"
                    f"åŸå§‹äº‹é¡¹æ•°: {len(events)}"
                )
                return self._build_response(config, key_final, [], {})

            self.logger.info(
                f"âœ… æ­¥éª¤4: Embeddingè®¡ç®—å®Œæˆï¼Œ{len(events_with_scores)} ä¸ªäº‹é¡¹æœ‰ç›¸ä¼¼åº¦åˆ†æ•°")

            # æ­¥éª¤5: é˜ˆå€¼è¿‡æ»¤
            filtered_events = self._filter_by_threshold(
                events_with_scores, threshold)
            if not filtered_events:
                # è®¡ç®—ç›¸ä¼¼åº¦ç»Ÿè®¡
                scores = [getattr(e, 'similarity_score', 0)
                          for e in events_with_scores]
                max_score = max(scores) if scores else 0
                avg_score = sum(scores) / len(scores) if scores else 0

                self.logger.warning(
                    f"âš ï¸ RRFæ­¥éª¤5å¤±è´¥ï¼šæ‰€æœ‰ {len(events_with_scores)} ä¸ªäº‹é¡¹éƒ½è¢«é˜ˆå€¼è¿‡æ»¤æ‰äº†ã€‚"
                    f"\n  å½“å‰é˜ˆå€¼: {threshold}"
                    f"\n  æœ€é«˜ç›¸ä¼¼åº¦: {max_score:.4f}"
                    f"\n  å¹³å‡ç›¸ä¼¼åº¦: {avg_score:.4f}"
                    f"\n  å»ºè®®ï¼šé™ä½ threshold å‚æ•°ï¼ˆå½“å‰={threshold}ï¼‰"
                )
                return self._build_response(config, key_final, [], {})

            # æ­¥éª¤6-7: BM25 + RRF èåˆæ’åºï¼ˆç»‘å®šæ‰§è¡Œï¼‰
            final_events = await self._rank_by_rrf(
                filtered_events, query, top_k, rrf_k
            )

            self.logger.info(
                f"RRFæœç´¢å®Œæˆ: è¿”å› {len(final_events)} ä¸ªäº‹é¡¹ "
                f"(åŸå§‹={len(events)}, é˜ˆå€¼è¿‡æ»¤å={len(filtered_events)}, "
                f"Top-K={top_k})"
            )

            # === æ„å»ºReranké˜¶æ®µçº¿ç´¢ ===
            # è®¡ç®— top-kÃ—3 ç”¨äºç”Ÿæˆ intermediate çº¿ç´¢
            intermediate_count = min(top_k * 3, len(final_events))
            intermediate_events = final_events[:intermediate_count]

            rerank_clues = self._build_rerank_clues(
                config,
                key_final,
                intermediate_events,  # ä¼ å…¥ top-kÃ—3 äº‹é¡¹ï¼ˆç”¨äºç”Ÿæˆä¸­é—´çº¿ç´¢ï¼‰
                final_events[:top_k], # ä¼ å…¥ Top-K äº‹é¡¹ï¼ˆç”¨äºç”Ÿæˆ final çº¿ç´¢ï¼‰
                event_to_clues
            )
            config.rerank_clues = rerank_clues
            self.logger.info(f"âœ¨ Rerankçº¿ç´¢å·²æ„å»º (entityâ†’eventç›´æ¥è¿æ¥)")

            return self._build_response(config, key_final, final_events, event_to_clues)

        except Exception as e:
            self.logger.error(f"RRFæœç´¢å¤±è´¥: {e}", exc_info=True)
            # åˆ¤æ–­æ˜¯å¦åº”è¯¥è¿”å› final_query
            # å¦‚æœå¯ç”¨äº†queryé‡å†™åŠŸèƒ½ï¼ˆenable_query_rewrite=Trueï¼‰ï¼Œåˆ™è¿”å›é‡å†™åçš„query
            # å¦åˆ™è¿”å› None
            final_query = config.query if config.enable_query_rewrite else None
            return {
                "events": [],
                "clues": {
                    "origin_query": config.original_query,
                    "final_query": final_query,
                    "query_entities": [],
                    "recall_entities": []
                }
            }

    async def _get_events_from_keys(
        self,
        key_final: List[Dict[str, Any]],
        source_config_ids: List[str]  # ğŸ†• æ”¹ä¸ºåˆ—è¡¨æ”¯æŒå¤šæº
    ) -> Tuple[List[SourceEvent], Dict[str, List[Dict]]]:
        """
        æ­¥éª¤1-3: ä» keys æŸ¥æ‰¾å…³è”äº‹é¡¹ï¼ˆç›´æ¥ä½¿ç”¨ key_id â†’ äº‹ä»¶å…³è” â†’ å»é‡ï¼‰

        ä¼˜åŒ–ï¼šå®Œå…¨è·³è¿‡ Entity è¡¨æŸ¥è¯¢ï¼Œç›´æ¥ä½¿ç”¨ key_idï¼ˆkey_id å°±æ˜¯ entity_idï¼‰

        æ–°å¢åŠŸèƒ½ï¼šæ„å»º event_to_clues æ˜ å°„è¡¨ï¼Œè®°å½•äº‹é¡¹ä¸å®ä½“çš„å…³è”å…³ç³»

        Args:
            key_final: å…³é”®å®ä½“åˆ—è¡¨ï¼ˆæ¯ä¸ª key çš„ key_id å°±æ˜¯ Entity è¡¨çš„ idï¼‰
            source_config_ids: æ•°æ®æºIDåˆ—è¡¨ï¼ˆğŸ†• æ”¯æŒå¤šæºï¼‰

        Returns:
            Tuple[List[SourceEvent], Dict[str, List[Dict]]]:
                - events: å»é‡åçš„äº‹é¡¹åˆ—è¡¨
                - event_to_clues: äº‹é¡¹IDåˆ°å®ä½“åˆ—è¡¨çš„æ˜ å°„ {event_id: [entity1, entity2, ...]}
        """
        # 1. ç›´æ¥æå– key_idsï¼ˆå°±æ˜¯ entity_idsï¼‰
        entity_ids = [key["key_id"] for key in key_final]

        # 2. åˆ›å»º key_id â†’ key å¯¹è±¡çš„æ˜ å°„ï¼ˆå°† key_id é‡å‘½åä¸º idï¼‰
        key_info_map = {}
        for key in key_final:
            # åˆ›å»º key çš„å‰¯æœ¬ï¼Œå°† key_id é‡å‘½åä¸º id
            key_copy = key.copy()
            if "key_id" in key_copy:
                key_copy["id"] = key_copy.pop("key_id")
            key_info_map[key["key_id"]] = key_copy

        self.logger.info(f"ä» key_final æå– {len(entity_ids)} ä¸ª entity_ids")

        async with self.session_factory() as session:
            # 3. ç›´æ¥é€šè¿‡ EventEntity æŸ¥æ‰¾ç›¸å…³äº‹ä»¶ï¼ˆè·³è¿‡ Entity è¡¨æŸ¥è¯¢ï¼‰
            event_entity_query = (
                select(EventEntity.event_id, EventEntity.entity_id)
                .join(SourceEvent, EventEntity.event_id == SourceEvent.id)
                .where(
                    and_(
                        SourceEvent.source_config_id.in_(source_config_ids),  # ğŸ†• å¤šæºè¿‡æ»¤
                        EventEntity.entity_id.in_(entity_ids)  # ç›´æ¥ä½¿ç”¨ key_ids
                    )
                )
                .distinct()
            )

            event_result = await session.execute(event_entity_query)
            event_relations = event_result.fetchall()  # è·å– (event_id, entity_id) å…ƒç»„

            self.logger.info(f"æŸ¥è¯¢åˆ° {len(event_relations)} æ¡ event-entity å…³ç³»")

            # 4. æ„å»º event_id â†’ clues æ˜ å°„ï¼ˆä¸€æ¬¡éå†å®Œæˆï¼‰
            event_to_clues = {}
            for event_id, entity_id in event_relations:
                if event_id not in event_to_clues:
                    event_to_clues[event_id] = []

                # ç›´æ¥ä» key_info_map è·å–ï¼ˆentity_id å°±æ˜¯ key_idï¼‰
                key_info = key_info_map.get(entity_id)
                if key_info:
                    event_to_clues[event_id].append(key_info)

            # 5. æå–æ‰€æœ‰å”¯ä¸€çš„ event_ids
            event_ids = list(event_to_clues.keys())

            if not event_ids:
                self.logger.warning("æœªæ‰¾åˆ°ç›¸å…³äº‹ä»¶")
                return []

            self.logger.info(f"æ‰¾åˆ° {len(event_ids)} ä¸ªå…³è”äº‹ä»¶ï¼ˆå·²å»é‡ï¼‰")

            # 6. æŸ¥è¯¢æ‰€æœ‰äº‹é¡¹çš„è¯¦ç»†ä¿¡æ¯ï¼ˆé¢„åŠ è½½ source å’Œ article å…³ç³»ï¼‰
            event_query = (
                select(SourceEvent)
                .options(
                    selectinload(SourceEvent.event_associations),  # é¢„åŠ è½½å…³è”å…³ç³»
                    selectinload(SourceEvent.source),  # é¢„åŠ è½½ SourceConfig
                    selectinload(SourceEvent.article)  # é¢„åŠ è½½ Article
                )
                .where(
                    and_(
                        SourceEvent.source_config_id.in_(source_config_ids),  # ğŸ†• å¤šæºè¿‡æ»¤
                        SourceEvent.id.in_(event_ids)
                    )
                )
            )

            event_detail_result = await session.execute(event_query)
            events = event_detail_result.scalars().all()

            original_count = len(events)
            self.logger.info(f"æŸ¥è¯¢åˆ° {original_count} ä¸ªäº‹é¡¹è¯¦ç»†ä¿¡æ¯")

            if not events:
                self.logger.warning("æœªæ‰¾åˆ°äº‹é¡¹è¯¦ç»†ä¿¡æ¯")
                return []

            # ä¸ºæ¯ä¸ªäº‹é¡¹æ·»åŠ  source_name å’Œ document_name å±æ€§
            for event in events:
                event.source_name = event.source.name if event.source else ""
                event.document_name = event.article.title if event.article else ""

            # 7. äº‹é¡¹å»é‡ï¼ˆé˜²æ­¢åŒä¸€ä¸ªäº‹é¡¹å¤šæ¬¡è¿”å›ï¼‰
            unique_events = {}
            for event in events:
                event_id = event.id
                if event_id not in unique_events:
                    unique_events[event_id] = event

            events = list(unique_events.values())
            unique_count = len(events)
            duplicate_count = original_count - unique_count

            if duplicate_count > 0:
                self.logger.info(
                    f"äº‹é¡¹å»é‡å®Œæˆ: å»é‡å‰={original_count}ä¸ª, "
                    f"å»é‡å={unique_count}ä¸ª, "
                    f"å»é™¤é‡å¤={duplicate_count}ä¸ª"
                )

            # 8. è¾“å‡º event_to_clues æ˜ å°„è¡¨ç»Ÿè®¡ä¿¡æ¯
            clues_stats = [len(clues) for clues in event_to_clues.values()]
            if clues_stats:
                self.logger.info(
                    f"âœ… event_to_cluesç»Ÿè®¡: å¹³å‡={sum(clues_stats)/len(clues_stats):.1f}ä¸ªå®ä½“/äº‹é¡¹, "
                    f"æœ€å¤š={max(clues_stats)}ä¸ª, æœ€å°‘={min(clues_stats)}ä¸ª"
                )

            return events, event_to_clues

    async def _calculate_embedding_similarity(
        self,
        events: List[SourceEvent],
        query_vector: List[float]
    ) -> List[SourceEvent]:
        """
        æ­¥éª¤4: è®¡ç®— Embedding ç›¸ä¼¼åº¦ï¼ˆç²—æ’ï¼‰

        ä» ES æ‰¹é‡è·å–äº‹é¡¹å‘é‡ï¼Œè®¡ç®—ä¸ query çš„åŠ æƒä½™å¼¦ç›¸ä¼¼åº¦
        æƒé‡: title_vector * 0.2 + content_vector * 0.8

        Args:
            events: äº‹é¡¹åˆ—è¡¨
            query_vector: æŸ¥è¯¢å‘é‡

        Returns:
            List[SourceEvent]: é™„åŠ äº† similarity_score å±æ€§çš„äº‹é¡¹åˆ—è¡¨
        """
        self.logger.info(f"å¼€å§‹ä»ESæ‰¹é‡è·å– {len(events)} ä¸ªäº‹é¡¹çš„å‘é‡...")
        vector_fetch_start = time.perf_counter()

        # æå–æ‰€æœ‰äº‹é¡¹ID
        event_ids = [event.id for event in events]

        # åˆ†æ‰¹å¤„ç†ï¼Œé¿å…ä¸€æ¬¡æ€§æŸ¥è¯¢è¿‡å¤š
        batch_size = 100  # ESå¯ä»¥å¤„ç†æ›´å¤§çš„æ‰¹æ¬¡
        events_with_vectors = []
        missing_vector_count = 0

        for i in range(0, len(event_ids), batch_size):
            batch_event_ids = event_ids[i:i + batch_size]
            self.logger.debug(
                f"  å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}: {len(batch_event_ids)} ä¸ªäº‹é¡¹")

            # æ‰¹é‡è·å–äº‹é¡¹æ•°æ®ï¼ˆåŒ…å«å‘é‡ï¼‰
            batch_event_data = await self.event_repo.get_events_by_ids(batch_event_ids)
            # åˆ›å»º event_id åˆ°æ•°æ®çš„æ˜ å°„
            event_data_map = {
                data.get("event_id"): data
                for data in batch_event_data
                if isinstance(data, dict) and "event_id" in data
            }

            # åŒ¹é…åŸå§‹ event å¯¹è±¡å’Œ ES æ•°æ®
            for event in events[i:i + batch_size]:
                event_data = event_data_map.get(event.id)

                if not event_data:
                    self.logger.warning(f"äº‹é¡¹ {event.id} åœ¨ESä¸­æœªæ‰¾åˆ°æ•°æ®")
                    missing_vector_count += 1
                    continue

                # è·å–æ ‡é¢˜å‘é‡å’Œå†…å®¹å‘é‡
                title_vector = event_data.get("title_vector")
                content_vector = event_data.get("content_vector")

                # è‡³å°‘éœ€è¦ä¸€ä¸ªå‘é‡
                if title_vector is None and content_vector is None:
                    self.logger.warning(f"äº‹é¡¹ {event.id} æ— å‘é‡æ•°æ®")
                    missing_vector_count += 1
                    continue

                # ä¿å­˜äº‹é¡¹åŠå…¶å‘é‡
                events_with_vectors.append({
                    'event': event,
                    'title_vector': title_vector,
                    'content_vector': content_vector
                })

        vector_fetch_time = time.perf_counter() - vector_fetch_start
        self.logger.info(
            f"âœ… å‘é‡è·å–å®Œæˆï¼ŒæˆåŠŸ: {len(events_with_vectors)} ä¸ªï¼Œ"
            f"ç¼ºå¤±å‘é‡: {missing_vector_count} ä¸ªï¼Œ"
            f"è€—æ—¶: {vector_fetch_time:.3f}ç§’"
        )

        if not events_with_vectors:
            self.logger.warning("æ‰€æœ‰äº‹é¡¹éƒ½æ²¡æœ‰å‘é‡æ•°æ®ï¼Œæ— æ³•è®¡ç®—ç›¸ä¼¼åº¦")
            return []

        # æ‰¹é‡è®¡ç®—åŠ æƒç›¸ä¼¼åº¦
        self.logger.info(f"å¼€å§‹æ‰¹é‡è®¡ç®— {len(events_with_vectors)} ä¸ªäº‹é¡¹çš„åŠ æƒç›¸ä¼¼åº¦...")
        similarity_start = time.perf_counter()

        # æå–æ‰€æœ‰æ ‡é¢˜å‘é‡å’Œå†…å®¹å‘é‡
        title_vectors = [item.get('title_vector')
                         for item in events_with_vectors]
        content_vectors = [item.get('content_vector')
                           for item in events_with_vectors]

        # ä½¿ç”¨åŠ æƒç›¸ä¼¼åº¦è®¡ç®—
        similarities = self._calculate_weighted_similarity(
            query_vector=query_vector,
            title_vectors=title_vectors,
            content_vectors=content_vectors,
            title_weight=0.2,
            content_weight=0.8
        )

        similarity_time = time.perf_counter() - similarity_start
        self.logger.info(
            f"åŠ æƒç›¸ä¼¼åº¦è®¡ç®—å®Œæˆï¼Œè€—æ—¶: {similarity_time:.4f}ç§’ï¼Œ"
            f"å¹³å‡æ¯ä¸ª: {similarity_time/len(similarities):.6f}ç§’"
        )

        # é™„åŠ ç›¸ä¼¼åº¦åˆ°äº‹é¡¹å¯¹è±¡
        events_with_scores = []

        for idx, (item, similarity) in enumerate(zip(events_with_vectors, similarities)):
            event = item['event']

            # ä¸ºäº‹é¡¹å¯¹è±¡é™„åŠ ç›¸ä¼¼åº¦å±æ€§
            event.similarity_score = float(similarity)
            events_with_scores.append(event)

        return events_with_scores

    def _calculate_weighted_similarity(
        self,
        query_vector: List[float],
        title_vectors: List[List[float]],
        content_vectors: List[List[float]],
        title_weight: float = 0.2,
        content_weight: float = 0.8
    ) -> np.ndarray:
        """
        è®¡ç®—åŠ æƒç›¸ä¼¼åº¦ï¼šqueryåˆ†åˆ«ä¸titleå’Œcontentæ‰¹é‡è®¡ç®—ç›¸ä¼¼åº¦ï¼Œç„¶åæŒ‰æƒé‡åˆå¹¶

        ä¼˜åŒ–ï¼šä½¿ç”¨ numpy é«˜çº§ç´¢å¼•å‡å°‘ä¸­é—´åˆ—è¡¨æ“ä½œ

        Args:
            query_vector: æŸ¥è¯¢å‘é‡
            title_vectors: æ ‡é¢˜å‘é‡åˆ—è¡¨ï¼ˆå¯èƒ½åŒ…å«Noneï¼‰
            content_vectors: å†…å®¹å‘é‡åˆ—è¡¨ï¼ˆå¯èƒ½åŒ…å«Noneï¼‰
            title_weight: æ ‡é¢˜ç›¸ä¼¼åº¦æƒé‡ï¼Œé»˜è®¤0.2
            content_weight: å†…å®¹ç›¸ä¼¼åº¦æƒé‡ï¼Œé»˜è®¤0.8

        Returns:
            åŠ æƒç›¸ä¼¼åº¦æ•°ç»„
        """
        try:
            num_items = len(title_vectors)

            # è½¬æ¢ä¸º numpy æ•°ç»„ä»¥ä¾¿å‘é‡åŒ–æ“ä½œ
            query_array = np.array(query_vector)

            # åˆå§‹åŒ–ç»“æœæ•°ç»„
            weighted_similarities = np.zeros(num_items, dtype=np.float32)

            # 1. æ‰¹é‡è®¡ç®—æ ‡é¢˜ç›¸ä¼¼åº¦ï¼ˆä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼ + numpy é«˜çº§ç´¢å¼•ï¼‰
            valid_title_mask = np.array(
                [vec is not None for vec in title_vectors])
            if valid_title_mask.any():
                valid_title_vectors = np.array(
                    [vec for vec in title_vectors if vec is not None], dtype=np.float32)
                title_sims = self._batch_cosine_similarity(
                    query_array, valid_title_vectors)
                weighted_similarities[valid_title_mask] += title_weight * title_sims

            # 2. æ‰¹é‡è®¡ç®—å†…å®¹ç›¸ä¼¼åº¦
            valid_content_mask = np.array(
                [vec is not None for vec in content_vectors])
            if valid_content_mask.any():
                valid_content_vectors = np.array(
                    [vec for vec in content_vectors if vec is not None], dtype=np.float32)
                content_sims = self._batch_cosine_similarity(
                    query_array, valid_content_vectors)
                weighted_similarities[valid_content_mask] += content_weight * content_sims

            return weighted_similarities

        except Exception as e:
            self.logger.error(f"åŠ æƒç›¸ä¼¼åº¦è®¡ç®—é”™è¯¯: {e}")
            return np.zeros(num_items)

    def _batch_cosine_similarity(
        self,
        query_vector: np.ndarray,
        target_vectors: np.ndarray
    ) -> np.ndarray:
        """
        æ‰¹é‡è®¡ç®—queryå‘é‡ä¸å¤šä¸ªç›®æ ‡å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦

        ä¼˜åŒ–ï¼šä½¿ç”¨ float32 å‡å°‘å†…å­˜å ç”¨å’Œè®¡ç®—é‡ï¼Œç›´æ¥æ¥æ”¶ numpy æ•°ç»„

        Args:
            query_vector: æŸ¥è¯¢å‘é‡ï¼ˆnumpyæ•°ç»„ï¼‰
            target_vectors: ç›®æ ‡å‘é‡æ•°ç»„ï¼ˆ2D numpyæ•°ç»„ï¼‰

        Returns:
            ä½™å¼¦ç›¸ä¼¼åº¦æ•°ç»„
        """
        try:
            # ç¡®ä¿æ˜¯ float32 ç±»å‹
            if query_vector.dtype != np.float32:
                query_vector = query_vector.astype(np.float32)
            if target_vectors.dtype != np.float32:
                target_vectors = target_vectors.astype(np.float32)

            # è®¡ç®—ç‚¹ç§¯ï¼ˆä½¿ç”¨çŸ©é˜µä¹˜æ³•ï¼Œæ›´å¿«ï¼‰
            dot_products = np.dot(target_vectors, query_vector)

            # è®¡ç®—èŒƒæ•°ï¼ˆä½¿ç”¨ axis=1 å‘é‡åŒ–è®¡ç®—ï¼‰
            query_norm = np.linalg.norm(query_vector)
            target_norms = np.linalg.norm(target_vectors, axis=1)

            # è®¡ç®—ç›¸ä¼¼åº¦ï¼ˆé¿å…é™¤ä»¥é›¶ï¼Œä½¿ç”¨å‘é‡åŒ–æ“ä½œï¼‰
            denominators = target_norms * query_norm
            similarities = np.divide(
                dot_products,
                denominators,
                out=np.zeros_like(dot_products),
                where=denominators > 1e-8  # ä½¿ç”¨å°é˜ˆå€¼è€Œä¸æ˜¯0ï¼Œæ›´ç¨³å®š
            )

            return similarities

        except Exception as e:
            self.logger.error(f"æ‰¹é‡ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—é”™è¯¯: {e}")
            return np.zeros(len(target_vectors), dtype=np.float32)

    def _filter_by_threshold(
        self,
        events: List[SourceEvent],
        threshold: float
    ) -> List[SourceEvent]:
        """
        æ­¥éª¤5: é˜ˆå€¼è¿‡æ»¤

        è¿‡æ»¤æ‰ Embedding ç›¸ä¼¼åº¦ä½äºé˜ˆå€¼çš„äº‹é¡¹

        Args:
            events: é™„åŠ äº† similarity_score çš„äº‹é¡¹åˆ—è¡¨
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼

        Returns:
            List[SourceEvent]: è¿‡æ»¤åçš„äº‹é¡¹åˆ—è¡¨
        """
        before_filter_count = len(events)
        filtered_events = [
            event for event in events
            if event.similarity_score >= threshold
        ]
        after_filter_count = len(filtered_events)
        filtered_count = before_filter_count - after_filter_count

        self.logger.info("=" * 80)
        self.logger.info(
            f"é˜ˆå€¼è¿‡æ»¤å®Œæˆ: é˜ˆå€¼={threshold:.2f}, "
            f"è¿‡æ»¤å‰={before_filter_count}ä¸ª, "
            f"è¿‡æ»¤å={after_filter_count}ä¸ª, "
            f"è¿‡æ»¤æ‰={filtered_count}ä¸ª"
        )

        if not filtered_events:
            self.logger.warning(f"é˜ˆå€¼è¿‡æ»¤åæ²¡æœ‰å‰©ä½™äº‹é¡¹ï¼ˆæ‰€æœ‰äº‹é¡¹ç›¸ä¼¼åº¦ < {threshold:.2f}ï¼‰")

        return filtered_events

    async def _rank_by_rrf(
        self,
        events: List[SourceEvent],
        query: str,
        top_k: int,
        rrf_k: int = 60
    ) -> List[SourceEvent]:
        """
        æ­¥éª¤7: RRF (Reciprocal Rank Fusion) èåˆæ’åº

        èåˆ Embedding ç›¸ä¼¼åº¦æ’åºå’Œ BM25 æ’åºçš„ç»“æœï¼Œè®¡ç®— RRF åˆ†æ•°

        RRF å…¬å¼ï¼š
        RRF_score(d) = Î£ 1/(k + rank_i(d))

        åœ¨æˆ‘ä»¬çš„åœºæ™¯ä¸­ï¼š
        RRF_score(event) = 1/(k + embedding_rank) + 1/(k + bm25_rank)

        Args:
            events: é€šè¿‡ Embedding é˜ˆå€¼è¿‡æ»¤çš„äº‹é¡¹åˆ—è¡¨ï¼ˆå·²æœ‰ similarity_scoreï¼‰
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›æ•°é‡
            rrf_k: RRF å¸¸æ•°ï¼Œé»˜è®¤60ï¼ˆå¹³è¡¡ä¸åŒæ’åºç³»ç»Ÿçš„å½±å“ï¼‰

        Returns:
            List[SourceEvent]: RRF èåˆæ’åºåçš„äº‹é¡¹åˆ—è¡¨ï¼ˆé™„åŠ  rrf_score å±æ€§ï¼‰
        """
        try:
            self.logger.info(f"å¼€å§‹ RRF èåˆæ’åºï¼Œå¤„ç† {len(events)} ä¸ªäº‹é¡¹ï¼Œk={rrf_k}...")
            rrf_start = time.perf_counter()

            # ç¬¬1æ­¥ï¼šæŒ‰ Embedding ç›¸ä¼¼åº¦æ’åºï¼Œè·å–æ’å
            self.logger.debug("æ­¥éª¤1: æŒ‰ Embedding ç›¸ä¼¼åº¦æ’åº...")
            embedding_sorted = sorted(
                events,
                key=lambda x: x.similarity_score,
                reverse=True
            )

            # ä¸ºæ¯ä¸ªäº‹é¡¹é™„åŠ  Embedding æ’åï¼ˆç›´æ¥è®¾ç½®å±æ€§ï¼Œé¿å…åˆ›å»ºå­—å…¸ï¼‰
            for rank, event in enumerate(embedding_sorted, start=1):
                event.embedding_rank = rank

            # ç¬¬2æ­¥ï¼šè®¡ç®— BM25 åˆ†æ•°å¹¶æ’åºï¼Œè·å–æ’å
            self.logger.debug("æ­¥éª¤2: è®¡ç®— BM25 åˆ†æ•°å¹¶æ’åº...")
            events_with_bm25 = await self._calculate_bm25_scores(events, query)

            bm25_sorted = sorted(
                events_with_bm25,
                key=lambda x: x.bm25_score,
                reverse=True
            )

            # ä¸ºæ¯ä¸ªäº‹é¡¹é™„åŠ  BM25 æ’å
            for rank, event in enumerate(bm25_sorted, start=1):
                event.bm25_rank = rank

            # ç¬¬3æ­¥ï¼šè®¡ç®— RRF åˆ†æ•°ï¼ˆå‘é‡åŒ–æ“ä½œï¼‰
            self.logger.debug("æ­¥éª¤3: è®¡ç®— RRF èåˆåˆ†æ•°...")
            default_rank = len(events) + 1

            for event in events:
                # ç›´æ¥ä»å±æ€§è¯»å–ï¼Œé¿å…å­—å…¸æŸ¥æ‰¾
                embedding_rank = getattr(event, 'embedding_rank', default_rank)
                bm25_rank = getattr(event, 'bm25_rank', default_rank)

                # RRF å…¬å¼ï¼š1/(k + rank1) + 1/(k + rank2)
                rrf_score = (1.0 / (rrf_k + embedding_rank)) + \
                    (1.0 / (rrf_k + bm25_rank))
                event.rrf_score = rrf_score

            # ç¬¬4æ­¥ï¼šæŒ‰ RRF åˆ†æ•°æ’åºï¼ˆé™åºï¼‰
            self.logger.debug("æ­¥éª¤4: æŒ‰ RRF åˆ†æ•°æ’åº...")
            rrf_sorted = sorted(
                events,
                key=lambda x: x.rrf_score,
                reverse=True
            )

            # ç¬¬5æ­¥ï¼šå– Top-K
            result_events = rrf_sorted[:top_k]

            rrf_time = time.perf_counter() - rrf_start
            self.logger.info(
                f"RRF èåˆæ’åºå®Œæˆï¼Œè€—æ—¶: {rrf_time:.4f}ç§’ï¼Œ"
                f"è¿”å› {len(result_events)} ä¸ªäº‹é¡¹"
            )

            # è®°å½•è¯¦ç»†ç»“æœ
            self.logger.info("=" * 80)
            self.logger.info(
                f"RRF èåˆæ’åºç»“æœï¼ˆTop {min(len(result_events), top_k)}ï¼‰ï¼š")
            self.logger.info("-" * 80)

            for i, event in enumerate(result_events[:top_k], 1):
                title = (event.title or "æ— æ ‡é¢˜")[:50]
                embedding_sim = getattr(event, 'similarity_score', 0.0)
                embedding_rank = getattr(event, 'embedding_rank', 0)
                bm25_score = getattr(event, 'bm25_score', 0.0)
                bm25_rank = getattr(event, 'bm25_rank', 0)
                rrf_score = getattr(event, 'rrf_score', 0.0)

                self.logger.info(
                    f"Rank {i}: {title}\n"
                    f"  Embedding: score={embedding_sim:.4f}, rank={embedding_rank}\n"
                    f"  BM25: score={bm25_score:.4f}, rank={bm25_rank}\n"
                    f"  RRF: score={rrf_score:.6f}"
                )

            self.logger.info("=" * 80)

            return result_events

        except Exception as e:
            self.logger.error(f"RRF èåˆæ’åºå¤±è´¥: {e}", exc_info=True)
            # é™çº§æ–¹æ¡ˆï¼šæŒ‰ Embedding ç›¸ä¼¼åº¦æ’åº
            self.logger.warning("RRF èåˆå¤±è´¥ï¼Œé™çº§ä¸º Embedding ç›¸ä¼¼åº¦æ’åº")
            sorted_events = sorted(
                events,
                key=lambda x: x.similarity_score,
                reverse=True
            )
            return sorted_events[:top_k]

    async def _calculate_bm25_scores(
        self,
        events: List[SourceEvent],
        query: str
    ) -> List[SourceEvent]:
        """
        è®¡ç®— BM25 åˆ†æ•°ï¼ˆä¸è¿›è¡Œæ’åºå’Œæˆªæ–­ï¼Œä»…è®¡ç®—åˆ†æ•°ï¼‰

        ä½¿ç”¨ fast_mode è·³è¿‡ spaCy åˆ†è¯ï¼Œåªç”¨ jieba + ç©ºæ ¼åˆ†è¯ï¼Œæå‡æ€§èƒ½

        Args:
            events: äº‹é¡¹åˆ—è¡¨
            query: æŸ¥è¯¢æ–‡æœ¬

        Returns:
            List[SourceEvent]: é™„åŠ äº† bm25_score çš„äº‹é¡¹åˆ—è¡¨
        """
        try:
            bm25_start = time.perf_counter()

            # è·å–å…¨å±€å•ä¾‹åˆ†è¯å™¨
            tokenizer = get_mixed_tokenizer()

            # é¢„å¤„ç†æŸ¥è¯¢ï¼ˆåªéœ€ä¸€æ¬¡ï¼‰
            query_lower = query.lower()

            # æ„å»ºå¹¶åˆ†è¯æ–‡æ¡£è¯­æ–™åº“ï¼ˆä¸€æ¬¡æ€§å®Œæˆï¼Œå‡å°‘ä¸­é—´åˆ—è¡¨ï¼‰
            tokenize_start = time.perf_counter()
            tokenized_corpus = []

            for event in events:
                # ä½¿ç”¨ join ä»£æ›¿ f-stringï¼Œå‡å°‘å†…å­˜åˆ†é…
                parts = []
                if event.title:
                    parts.append(event.title)
                if event.summary:
                    parts.append(event.summary)
                if event.content:
                    parts.append(event.content)

                # ä¸€æ¬¡æ€§æ‹¼æ¥å¹¶å°å†™è½¬æ¢
                doc_text = ' '.join(parts).lower()

                # ç›´æ¥åˆ†è¯å¹¶æ·»åŠ åˆ°ç»“æœï¼ˆé¿å…å…ˆåˆ›å»º corpus åˆ—è¡¨ï¼‰
                tokenized_corpus.append(
                    tokenizer.tokenize(doc_text, fast_mode=True))

            # åˆ†è¯æŸ¥è¯¢
            tokenized_query = tokenizer.tokenize(query_lower, fast_mode=True)
            tokenize_time = time.perf_counter() - tokenize_start

            # æ—¥å¿—ï¼šå±•ç¤º query åˆ†è¯ç»“æœ
            self.logger.info(
                f"Query åˆ†è¯ç»“æœ: '{query}' -> {tokenized_query} "
                f"(å…± {len(tokenized_query)} ä¸ªè¯)"
            )

            # è®¡ç®— BM25 åˆ†æ•°ï¼ˆå»¶è¿Ÿå¯¼å…¥ï¼‰
            bm25_calc_start = time.perf_counter()
            try:
                from rank_bm25 import BM25Okapi
                bm25 = BM25Okapi(tokenized_corpus)
                scores = bm25.get_scores(tokenized_query)
            except ImportError:
                self.logger.warning("rank_bm25æœªå®‰è£…ï¼ŒBM25åˆ†æ•°å°†ä½¿ç”¨é»˜è®¤å€¼0")
                scores = [0.0] * len(events)
            bm25_calc_time = time.perf_counter() - bm25_calc_start

            # ä¸ºæ¯ä¸ªäº‹é¡¹é™„åŠ  BM25 åˆ†æ•°
            for event, score in zip(events, scores):
                event.bm25_score = float(score)

            bm25_total_time = time.perf_counter() - bm25_start
            self.logger.debug(
                f"BM25è®¡ç®—è€—æ—¶: æ€»è®¡={bm25_total_time:.4f}ç§’, "
                f"åˆ†è¯={tokenize_time:.4f}ç§’, BM25è®¡ç®—={bm25_calc_time:.4f}ç§’"
            )

            return events

        except Exception as e:
            self.logger.error(f"BM25 åˆ†æ•°è®¡ç®—å¤±è´¥: {e}", exc_info=True)
            # é™çº§ï¼šæ‰€æœ‰äº‹é¡¹åˆ†æ•°ä¸º 0
            for event in events:
                event.bm25_score = 0.0
            return events

    async def _rank_by_bm25(
        self,
        events: List[SourceEvent],
        query: str,
        top_k: int
    ) -> List[SourceEvent]:
        """
        æ­¥éª¤6: BM25 é‡æ’åºï¼ˆç²¾æ’ï¼‰

        ä½¿ç”¨ BM25 ç®—æ³•å¯¹é€šè¿‡ Embedding é˜ˆå€¼çš„äº‹é¡¹è¿›è¡Œå…³é”®è¯åŒ¹é…é‡æ’åº

        Args:
            events: é€šè¿‡ Embedding é˜ˆå€¼è¿‡æ»¤çš„äº‹é¡¹åˆ—è¡¨
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›æ•°é‡

        Returns:
            List[SourceEvent]: BM25 æ’åºåçš„äº‹é¡¹åˆ—è¡¨ï¼ˆé™„åŠ  bm25_score å’Œ bm25_rank å±æ€§ï¼‰
        """
        try:
            self.logger.info(f"å¼€å§‹ BM25 é‡æ’åºï¼Œå¤„ç† {len(events)} ä¸ªäº‹é¡¹...")
            bm25_start = time.perf_counter()

            # è·å–å…¨å±€å•ä¾‹åˆ†è¯å™¨
            tokenizer = get_mixed_tokenizer()

            # é¢„å¤„ç†æŸ¥è¯¢ï¼ˆåªéœ€ä¸€æ¬¡ï¼‰
            query_lower = query.lower()

            # æ„å»ºå¹¶åˆ†è¯æ–‡æ¡£è¯­æ–™åº“ï¼ˆä¸€æ¬¡æ€§å®Œæˆï¼‰
            self.logger.debug("å¼€å§‹å¯¹æ–‡æ¡£è¯­æ–™åº“å’ŒæŸ¥è¯¢è¿›è¡Œåˆ†è¯...")
            tokenize_start = time.perf_counter()
            tokenized_corpus = []

            for event in events:
                # ä½¿ç”¨ join ä»£æ›¿ f-stringï¼Œå‡å°‘å†…å­˜åˆ†é…
                parts = []
                if event.title:
                    parts.append(event.title)
                if event.summary:
                    parts.append(event.summary)
                if event.content:
                    parts.append(event.content)

                # ä¸€æ¬¡æ€§æ‹¼æ¥ã€å°å†™è½¬æ¢å¹¶åˆ†è¯
                doc_text = ' '.join(parts).lower()
                tokenized_corpus.append(
                    tokenizer.tokenize(doc_text, fast_mode=True))

            # åˆ†è¯æŸ¥è¯¢
            tokenized_query = tokenizer.tokenize(query_lower, fast_mode=True)

            tokenize_time = time.perf_counter() - tokenize_start
            self.logger.debug(f"åˆ†è¯å®Œæˆï¼Œè€—æ—¶: {tokenize_time:.4f}ç§’")

            # æ—¥å¿—ï¼šå±•ç¤º query åˆ†è¯ç»“æœ
            self.logger.info(
                f"Query åˆ†è¯ç»“æœ: '{query}' -> {tokenized_query} "
                f"(å…± {len(tokenized_query)} ä¸ªè¯)"
            )

            # è®¡ç®— BM25 åˆ†æ•°
            self.logger.debug("å¼€å§‹è®¡ç®— BM25 åˆ†æ•°...")
            bm25_calc_start = time.perf_counter()

            bm25 = BM25Okapi(tokenized_corpus)
            scores = bm25.get_scores(tokenized_query)

            bm25_calc_time = time.perf_counter() - bm25_calc_start
            self.logger.debug(f"BM25 åˆ†æ•°è®¡ç®—å®Œæˆï¼Œè€—æ—¶: {bm25_calc_time:.4f}ç§’")

            # ä¸ºæ¯ä¸ªäº‹é¡¹é™„åŠ  BM25 åˆ†æ•°
            events_with_bm25 = []
            for event, score in zip(events, scores):
                event.bm25_score = float(score)
                events_with_bm25.append(event)

            # æŒ‰ BM25 åˆ†æ•°æ’åºï¼ˆé™åºï¼‰
            sorted_events = sorted(
                events_with_bm25,
                key=lambda x: x.bm25_score,
                reverse=True
            )

            # ä¸ºæ¯ä¸ªäº‹é¡¹é™„åŠ  BM25 æ’å
            for rank, event in enumerate(sorted_events, start=1):
                event.bm25_rank = rank

            # å– Top-K
            result_events = sorted_events[:top_k]

            bm25_time = time.perf_counter() - bm25_start
            self.logger.info(
                f"BM25 é‡æ’åºå®Œæˆï¼Œè€—æ—¶: {bm25_time:.4f}ç§’ï¼Œ"
                f"è¿”å› {len(result_events)} ä¸ªäº‹é¡¹"
            )

            # è®°å½• Top K ç»“æœ
            self.logger.info("=" * 80)
            self.logger.info(
                f"BM25 é‡æ’åºç»“æœï¼ˆTop {min(len(result_events), top_k)}ï¼‰ï¼š")
            self.logger.info("-" * 80)

            for i, event in enumerate(result_events[:top_k], 1):
                title = (event.title or "æ— æ ‡é¢˜")[:50]
                embedding_sim = getattr(event, 'similarity_score', 0.0)
                bm25_score = getattr(event, 'bm25_score', 0.0)

                self.logger.info(
                    f"Rank {i}: {title} | "
                    f"Embedding={embedding_sim:.4f}, BM25={bm25_score:.4f}"
                )

            self.logger.info("=" * 80)

            return result_events

        except Exception as e:
            self.logger.error(f"BM25 é‡æ’åºå¤±è´¥: {e}", exc_info=True)
            # é™çº§æ–¹æ¡ˆï¼šæŒ‰ Embedding ç›¸ä¼¼åº¦æ’åº
            self.logger.warning("BM25 é‡æ’åºå¤±è´¥ï¼Œé™çº§ä¸º Embedding ç›¸ä¼¼åº¦æ’åº")
            sorted_events = sorted(
                events,
                key=lambda x: x.similarity_score,
                reverse=True
            )
            return sorted_events[:top_k]

    def _build_response(
        self,
        config: SearchConfig,
        key_final: List[Dict[str, Any]],
        events: List[SourceEvent],
        event_to_clues: Dict[str, List[Dict]]
    ) -> Dict[str, Any]:
        """
        æ„å»ºæ–°çš„å“åº”æ ¼å¼

        Args:
            config: æœç´¢é…ç½®å¯¹è±¡
            key_final: å¬å›çš„å®ä½“åˆ—è¡¨ï¼ˆkey-finalï¼‰
            events: äº‹é¡¹åˆ—è¡¨
            event_to_clues: äº‹é¡¹IDåˆ°å®ä½“åˆ—è¡¨çš„æ˜ å°„ {event_id: [entity1, entity2, ...]}

        Returns:
            Dict[str, Any]: åŒ…å«ä»¥ä¸‹å­—æ®µçš„å­—å…¸ï¼š
                - events: äº‹é¡¹å¯¹è±¡åˆ—è¡¨
                - clues: å¬å›çº¿ç´¢ä¿¡æ¯
                    - origin_query: åŸå§‹æŸ¥è¯¢
                    - final_query: LLMé‡å†™åçš„æŸ¥è¯¢ï¼ˆå¦‚æœæ²¡æœ‰é‡å†™åˆ™ä¸ºNoneï¼‰
                    - query_entities: æŸ¥è¯¢å¬å›çš„å®ä½“åˆ—è¡¨ï¼ˆkey_idæ”¹ä¸ºidï¼‰
                    - recall_entities: å¬å›çš„å®ä½“åˆ—è¡¨ï¼ˆkey_idæ”¹ä¸ºidï¼Œå»é™¤query_entitiesä¸­çš„å€¼ï¼‰
                    - event_entities: äº‹é¡¹ä¸å®ä½“çš„å…³è”æ˜ å°„è¡¨ {event_id: [entity1, entity2, ...]}
        """
        # 1. å¤„ç† query_entitiesï¼šå°† config.query_recalled_keys ä¸­çš„ key_id æ”¹ä¸º id
        query_entities = []
        query_key_ids = set()  # ç”¨äºåç»­è¿‡æ»¤

        for key in config.query_recalled_keys:
            key_copy = key.copy()
            if "key_id" in key_copy:
                key_id = key_copy.pop("key_id")
                key_copy["id"] = key_id
                query_key_ids.add(key_id)
            query_entities.append(key_copy)

        # 2. å¤„ç† recall_entitiesï¼šå°† key_final ä¸­çš„ key_id æ”¹ä¸º idï¼Œå¹¶è¿‡æ»¤æ‰ query_entities ä¸­çš„å€¼
        recall_entities = []

        for key in key_final:
            # è·å– key_id ç”¨äºè¿‡æ»¤åˆ¤æ–­
            key_id = key.get("key_id")

            # å¦‚æœè¿™ä¸ª key_id åœ¨ query_recalled_keys ä¸­ï¼Œåˆ™è·³è¿‡
            if key_id in query_key_ids:
                continue

            # å¤åˆ¶å¹¶é‡å‘½å key_id ä¸º id
            key_copy = key.copy()
            if "key_id" in key_copy:
                key_copy["id"] = key_copy.pop("key_id")
            recall_entities.append(key_copy)

        # 3. åˆ¤æ–­æ˜¯å¦åº”è¯¥è¿”å› final_query
        # å¦‚æœå¯ç”¨äº†queryé‡å†™åŠŸèƒ½ï¼ˆenable_query_rewrite=Trueï¼‰ï¼Œåˆ™è¿”å›é‡å†™åçš„query
        # å¦åˆ™è¿”å› None
        final_query = config.query if config.enable_query_rewrite and config.recall.use_fast_mode == False else None

        # 4. è¿‡æ»¤ event_to_cluesï¼Œåªä¿ç•™æœ€ç»ˆè¿”å›çš„äº‹é¡¹
        final_event_ids = {event.id for event in events}
        filtered_event_entities = {
            event_id: clues
            for event_id, clues in event_to_clues.items()
            if event_id in final_event_ids
        }

        # 5. æ„å»ºå“åº”
        response = {
            "events": events,  # äº‹é¡¹åˆ—è¡¨
            "clues": {
                "origin_query": config.original_query,  # åŸå§‹queryï¼ˆé‡å†™å‰ï¼‰
                "final_query": final_query,  # é‡å†™åçš„queryï¼ˆæ²¡æœ‰é‡å†™åˆ™ä¸ºNoneï¼‰
                "query_entities": query_entities,
                "recall_entities": recall_entities,
                "event_entities": filtered_event_entities  # åªåŒ…å«æœ€ç»ˆè¿”å›äº‹é¡¹çš„æº¯æºä¿¡æ¯
            }
        }

        self.logger.info(
            f"å“åº”æ„å»ºå®Œæˆ: origin_query='{config.original_query}', "
            f"final_query='{final_query}', "
            f"query_entities={len(query_entities)}ä¸ª, "
            f"recall_entities={len(recall_entities)}ä¸ª, "
            f"events={len(events)}ä¸ª, "
            f"event_entitiesæ˜ å°„={len(filtered_event_entities)}ä¸ª (è¿‡æ»¤å‰={len(event_to_clues)}ä¸ª)"
        )

        return response

    def _build_rerank_clues(
        self,
        config: SearchConfig,
        key_final: List[Dict[str, Any]],
        intermediate_events: List[SourceEvent],
        final_events: List[SourceEvent],
        event_to_clues: Dict[str, List[Dict]]
    ) -> List[Dict[str, Any]]:
        """
        æ„å»ºReranké˜¶æ®µçš„çº¿ç´¢ï¼ˆentity â†’ eventï¼‰

        ğŸ†• ä¿®æ”¹ï¼šåˆ†ä¸¤é˜¶æ®µç”Ÿæˆçº¿ç´¢
        1. ä¸º top-kÃ—3 äº‹é¡¹ç”Ÿæˆ intermediate çº¿ç´¢ï¼ˆæ™®é€šæ¨¡å¼å¯è§ï¼‰
        2. ä¸º Top-K äº‹é¡¹ç”Ÿæˆ final çº¿ç´¢ï¼ˆç²¾ç®€æ¨¡å¼é«˜äº®æ˜¾ç¤ºï¼‰

        Args:
            config: æœç´¢é…ç½®
            key_final: æœ€ç»ˆçš„keyåˆ—è¡¨
            intermediate_events: top-kÃ—3 äº‹é¡¹ï¼ˆç”¨äºç”Ÿæˆä¸­é—´çº¿ç´¢ï¼‰
            final_events: Top-K æœ€ç»ˆè¿”å›çš„äº‹é¡¹åˆ—è¡¨ï¼ˆç”¨äºç”Ÿæˆ final çº¿ç´¢ï¼‰
            event_to_clues: äº‹é¡¹IDåˆ°å®ä½“åˆ—è¡¨çš„æ˜ å°„

        Returns:
            Reranké˜¶æ®µçš„çº¿ç´¢åˆ—è¡¨ï¼ˆå…¼å®¹æ€§ä¿ç•™ï¼Œå®é™…çº¿ç´¢å·²è¿½åŠ åˆ°config.all_cluesï¼‰
        """
        # ğŸ†• åˆ›å»ºçº¿ç´¢æ„å»ºå™¨
        tracker = Tracker(config)

        # åˆ›å»ºkey_idåˆ°keyå¯¹è±¡çš„æ˜ å°„ï¼Œæ–¹ä¾¿æŸ¥æ‰¾æƒé‡ç­‰ä¿¡æ¯
        key_map = {key["key_id"]: key for key in key_final}

        # åˆ›å»ºæœ€ç»ˆäº‹é¡¹IDé›†åˆï¼Œç”¨äºåˆ¤æ–­
        final_event_ids = {event.id for event in final_events}

        # ========== ç¬¬ä¸€æ­¥ï¼šä¸º top-kÃ—3 äº‹é¡¹ç”Ÿæˆ intermediate çº¿ç´¢ ==========
        self.logger.info("")
        self.logger.info("=" * 80)
        self.logger.info(f"[RRF Rerank] ç”Ÿæˆ Intermediate çº¿ç´¢ (Top-{len(intermediate_events)} äº‹é¡¹)")
        self.logger.info("-" * 80)

        intermediate_clue_count = 0

        # éå† top-kÃ—3 äº‹é¡¹
        for rank, event in enumerate(intermediate_events, 1):
            # è·å–è¯¥äº‹é¡¹å…³è”çš„å®ä½“
            source_entities = event_to_clues.get(event.id, [])

            for entity in source_entities:
                # ä»key_mapä¸­è·å–å®Œæ•´çš„å®ä½“ä¿¡æ¯
                entity_info = key_map.get(entity["id"])
                if not entity_info:
                    # å¦‚æœæ‰¾ä¸åˆ°ï¼Œä½¿ç”¨event_to_cluesä¸­çš„åŸºæœ¬ä¿¡æ¯
                    entity_info = entity

                # æ„å»ºå®Œæ•´çš„å®ä½“å­—å…¸ï¼ˆç”¨äºæ ‡å‡†èŠ‚ç‚¹æ„å»ºï¼‰
                entity_dict = {
                    "key_id": entity["id"],
                    "id": entity["id"],
                    "name": entity.get("name", ""),
                    "type": entity_info.get("type", "unknown") if entity_info else "unknown",
                    "description": entity_info.get("description", "") if entity_info else ""
                }

                # ä½¿ç”¨æ ‡å‡†èŠ‚ç‚¹æ„å»ºå™¨
                entity_node = Tracker.build_entity_node(entity_dict)
                # æ„å»ºäº‹é¡¹èŠ‚ç‚¹ï¼ˆä½¿ç”¨trackerå®ä¾‹æ–¹æ³•ï¼‰
                event_node = tracker.get_or_create_event_node(
                    event,
                    "rerank",
                    recall_method="entity"
                )

                # è·å–RRFåˆ†æ•°ä½œä¸ºç½®ä¿¡åº¦ï¼Œfallbackåˆ°similarity_score
                confidence = getattr(event, 'rrf_score', None)
                if confidence is None or confidence == 0.0:
                    # Fallback: ä½¿ç”¨similarity_score
                    confidence = getattr(event, 'similarity_score', None)
                    if confidence is None or confidence == 0.0:
                        # æœ€ç»ˆfallback: ä½¿ç”¨entityæƒé‡
                        confidence = entity_info.get(
                            "weight", 0.0) if entity_info else 0.0

                # æ·»åŠ  intermediate çº¿ç´¢
                tracker.add_clue(
                    stage="rerank",
                    from_node=entity_node,
                    to_node=event_node,
                    confidence=confidence,
                    relation="å†…å®¹é‡æ’",
                    display_level="intermediate",  # intermediate çº§åˆ«
                    metadata={
                        "method": "rrf",
                        "entity_weight": entity_info.get("weight", 0.0) if entity_info else 0.0,
                        "rrf_score": getattr(event, 'rrf_score', None),
                        "similarity_score": getattr(event, 'similarity_score', None),
                        "bm25_score": getattr(event, 'bm25_score', None),
                        "embedding_rank": getattr(event, 'embedding_rank', None),
                        "bm25_rank": getattr(event, 'bm25_rank', None),
                        "rank": rank
                    }
                )
                intermediate_clue_count += 1

            # æ—¥å¿—ï¼ˆåªæ˜¾ç¤ºå‰10ä¸ªï¼‰
            if rank <= 10:
                title_preview = event.title[:40] if event.title else "æ— æ ‡é¢˜"
                self.logger.info(
                    f"  Rank {rank}: {event.id[:8]}... | "
                    f"å®ä½“æ•°={len(source_entities)} | "
                    f"æ ‡é¢˜: {title_preview}"
                )

        if len(intermediate_events) > 10:
            self.logger.info(f"  ... (è¿˜æœ‰ {len(intermediate_events) - 10} ä¸ªäº‹é¡¹)")

        self.logger.info("-" * 80)
        self.logger.info(f"Intermediate çº¿ç´¢ç»Ÿè®¡: entityâ†’event={intermediate_clue_count} æ¡")
        self.logger.info("=" * 80)

        # ========== ç¬¬äºŒæ­¥ï¼šä¸º Top-K ç”Ÿæˆ final çº¿ç´¢ ==========
        self.logger.info("")
        self.logger.info("ğŸ¯ [RRF Rerank Final] ç”Ÿæˆæœ€ç»ˆçº¿ç´¢ (display_level=final)")
        self.logger.info(f"   ä¸º Top-{len(final_events)} äº‹é¡¹ç”Ÿæˆ final çº¿ç´¢")

        final_clue_count = 0

        for rank, event in enumerate(final_events, 1):
            # è·å–è¯¥äº‹é¡¹å…³è”çš„å®ä½“
            source_entities = event_to_clues.get(event.id, [])

            for entity in source_entities:
                # ä»key_mapä¸­è·å–å®Œæ•´çš„å®ä½“ä¿¡æ¯
                entity_info = key_map.get(entity["id"])
                if not entity_info:
                    entity_info = entity

                # æ„å»ºå®Œæ•´çš„å®ä½“å­—å…¸
                entity_dict = {
                    "key_id": entity["id"],
                    "id": entity["id"],
                    "name": entity.get("name", ""),
                    "type": entity_info.get("type", "unknown") if entity_info else "unknown",
                    "description": entity_info.get("description", "") if entity_info else ""
                }

                # ä½¿ç”¨æ ‡å‡†èŠ‚ç‚¹æ„å»ºå™¨
                entity_node = Tracker.build_entity_node(entity_dict)
                # æ„å»ºäº‹é¡¹èŠ‚ç‚¹
                event_node = tracker.get_or_create_event_node(
                    event,
                    "rerank",
                    recall_method="entity"
                )

                # è·å–ç½®ä¿¡åº¦
                confidence = getattr(event, 'rrf_score', None)
                if confidence is None or confidence == 0.0:
                    confidence = getattr(event, 'similarity_score', None)
                    if confidence is None or confidence == 0.0:
                        confidence = entity_info.get("weight", 0.0) if entity_info else 0.0

                # æ·»åŠ  final çº¿ç´¢
                tracker.add_clue(
                    stage="rerank",
                    from_node=entity_node,
                    to_node=event_node,
                    confidence=confidence,
                    relation="æœ€ç»ˆäº‹é¡¹",
                    display_level="final",  # final çº§åˆ«
                    metadata={
                        "method": "final_result",
                        "step": "step_final",
                        "entity_weight": entity_info.get("weight", 0.0) if entity_info else 0.0,
                        "rrf_score": getattr(event, 'rrf_score', None),
                        "similarity_score": getattr(event, 'similarity_score', None),
                        "bm25_score": getattr(event, 'bm25_score', None),
                        "embedding_rank": getattr(event, 'embedding_rank', None),
                        "bm25_rank": getattr(event, 'bm25_rank', None),
                        "rank": rank
                    }
                )
                final_clue_count += 1

                self.logger.debug(
                    f"  Final: {entity['id'][:8]}... ('{entity.get('name', '')[:20]}') "
                    f"â†’ {event.id[:8]}... ('{event.title[:30]}', RRF={getattr(event, 'rrf_score', 0.0):.4f})"
                )

        self.logger.info(
            f"âœ… [RRF Rerank Final] ç”Ÿæˆäº† {final_clue_count} æ¡æœ€ç»ˆçº¿ç´¢"
        )
        self.logger.info(
            f"âœ… [RRF Rerank Final] å‰ç«¯å¯æ ¹æ®è¿™äº› final çº¿ç´¢åæ¨å®Œæ•´æ¨ç†è·¯å¾„ï¼š"
        )
        self.logger.info(f"   - Entityå¬å›: query â†’ entity â†’ event")
        self.logger.info("")

        self.logger.info(
            f"ğŸ” [Rerankæ€»è®¡] çº¿ç´¢ç»Ÿè®¡: intermediate={intermediate_clue_count}æ¡, final={final_clue_count}æ¡"
        )

        # è¿”å›ç©ºåˆ—è¡¨ï¼ˆå…¼å®¹æ€§ä¿ç•™ï¼Œå®é™…çº¿ç´¢å·²é€šè¿‡trackerè¿½åŠ åˆ°config.all_cluesï¼‰
        return []
