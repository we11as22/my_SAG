"""
äº‹é¡¹å¤„ç†å™¨

è´Ÿè´£ä»æ–‡ç« ç‰‡æ®µä¸­æå–äº‹é¡¹å’Œå®ä½“çš„æ ¸å¿ƒé€»è¾‘
"""

import uuid
from typing import Any, Dict, List, Optional

from sqlalchemy import or_, select

from sag.core.ai.base import BaseLLMClient
from sag.core.ai.models import LLMMessage, LLMRole
from sag.core.prompt.manager import PromptManager
from sag.db import get_session_factory
from sag.db.models import (
    SourceChunk,
    Entity,
    EntityType as DBEntityType,
    EventEntity,
    SourceEvent,
)
from sag.exceptions import ExtractError
from sag.modules.extract.config import ExtractConfig
from sag.modules.extract.parser import EntityValueParser
from sag.utils import get_logger

logger = get_logger("extract.processor")


class EventProcessor:
    """äº‹é¡¹å¤„ç†å™¨ï¼ˆæ ¸å¿ƒæå–é€»è¾‘ï¼‰"""

    def __init__(
        self,
        llm_client: BaseLLMClient,
        prompt_manager: PromptManager,
        config: ExtractConfig,
    ):
        """
        åˆå§‹åŒ–äº‹é¡¹å¤„ç†å™¨

        Args:
            llm_client: LLMå®¢æˆ·ç«¯
            prompt_manager: æç¤ºè¯ç®¡ç†å™¨
            config: æå–é…ç½®
        """
        self.llm_client = llm_client
        self.prompt_manager = prompt_manager
        self.config = config
        self.session_factory = get_session_factory()
        self.entity_types: List[DBEntityType] = []
        self.logger = get_logger("extract.processor")
        self.parser = EntityValueParser()  # ğŸ†• åˆå§‹åŒ–å€¼è§£æå™¨

    async def extract_from_sections(
        self, sections: List[SourceChunk], batch_index: int
    ) -> List[SourceEvent]:
        """
        ä»æ¥æºç‰‡æ®µæå–äº‹é¡¹ï¼ˆæ ¸å¿ƒæ–¹æ³•ï¼‰

        è¿™æ˜¯æœ€åº•å±‚çš„æå–é€»è¾‘ï¼Œå•æ¬¡LLMè°ƒç”¨

        Args:
            sections: æ¥æºç‰‡æ®µåˆ—è¡¨
            batch_index: æ‰¹æ¬¡ç´¢å¼•ï¼ˆç”¨äºæ—¥å¿—ï¼‰

        Returns:
            æå–çš„äº‹é¡¹åˆ—è¡¨

        Raises:
            ExtractError: æå–å¤±è´¥
        """
        # è¾“å…¥éªŒè¯
        if not sections:
            self.logger.warning(f"æ‰¹æ¬¡ {batch_index}: sections åˆ—è¡¨ä¸ºç©ºï¼Œè·³è¿‡æå–")
            return []

        try:
            # 1. æ„å»ºä¸Šä¸‹æ–‡
            context = self._build_context(sections)

            # 2. æ„å»ºæç¤ºè¯
            prompt = self._build_prompt(context)
            self.logger.info(f"æç¤ºè¯:: {prompt}")

            # 3. æ„å»ºJSON Schema
            schema = self._build_extraction_schema()

            # 4. è°ƒç”¨LLM
            messages = [LLMMessage(role=LLMRole.USER, content=prompt)]

            result = await self.llm_client.chat_with_schema(
                messages, response_schema=schema, temperature=0.3
            )

            # 5. è§£æç»“æœ -> SourceEvent å¯¹è±¡
            events = await self._parse_extraction_result(result, sections)

            self.logger.info(
                f"æ‰¹æ¬¡ {batch_index}: æå–äº† {len(events)} ä¸ªäº‹é¡¹",
                extra={"batch_index": batch_index, "event_count": len(events)},
            )

            return events

        except Exception as e:
            self.logger.error(f"æ‰¹æ¬¡ {batch_index} æå–å¤±è´¥: {e}", exc_info=True)
            raise ExtractError(f"æ‰¹æ¬¡ {batch_index} æï¿½ï¿½ï¿½å¤±è´¥: {e}") from e

    async def extract_events_without_entities(
        self, sections: List[SourceChunk], batch_index: int
    ) -> List[SourceEvent]:
        """
        é˜¶æ®µ1ï¼šæå–äº‹é¡¹ï¼ˆä¸å«å®ä½“å…³è”ï¼‰

        Args:
            sections: æ¥æºç‰‡æ®µåˆ—è¡¨
            batch_index: æ‰¹æ¬¡ç´¢å¼•

        Returns:
            ä¸å«å®ä½“å…³è”çš„äº‹é¡¹åˆ—è¡¨
        """
        try:
            # 1. æ„å»ºä¸Šä¸‹æ–‡
            context = self._build_context(sections)

            # 2. æ„å»ºæç¤ºè¯
            prompt = self._build_prompt(context)

            # 3. æ„å»ºJSON Schema
            schema = self._build_extraction_schema()

            # 4. è°ƒç”¨LLM
            messages = [LLMMessage(role=LLMRole.USER, content=prompt)]

            self.logger.info(
                f"ğŸ“¦ æ‰¹æ¬¡ {batch_index}: å¼€å§‹æå–äº‹é¡¹ï¼ˆä¸å«å®ä½“ï¼‰ - ç‰‡æ®µæ•°={len(sections)}, "
                f"LLMæ¨¡å‹={self.llm_client.client.config.model}"
            )

            result = await self.llm_client.chat_with_schema(
                messages, response_schema=schema, temperature=0.3
            )

            # 5. è§£æç»“æœï¼ˆä¸å¤„ç†å®ä½“å…³è”ï¼‰
            events = await self._parse_extraction_result_without_entities(result, sections)

            self.logger.info(
                f"æ‰¹æ¬¡ {batch_index}: æå–äº† {len(events)} ä¸ªäº‹é¡¹ï¼ˆä¸å«å®ä½“ï¼‰",
                extra={"batch_index": batch_index, "event_count": len(events)},
            )

            return events

        except Exception as e:
            self.logger.error(
                f"âŒ æ‰¹æ¬¡ {batch_index} æå–å¤±è´¥ - æ¨¡å‹: {self.llm_client.client.config.model}, "
                f"ç‰‡æ®µæ•°: {len(sections)}, é”™è¯¯: {e}",
                exc_info=True
            )
            raise ExtractError(f"æ‰¹æ¬¡ {batch_index} æå–å¤±è´¥: {e}") from e

    async def process_entity_associations(
        self, events: List[SourceEvent], session=None
    ) -> List[SourceEvent]:
        """
        é˜¶æ®µ2ï¼šç»Ÿä¸€å¤„ç†æ‰€æœ‰äº‹é¡¹çš„å®ä½“å…³è”ï¼ˆå¸¦ session æ”¯æŒï¼‰

        Args:
            events: æ‰€æœ‰äº‹é¡¹åˆ—è¡¨ï¼ˆä¸å«å®ä½“å…³è”ï¼‰
            session: æ•°æ®åº“ sessionï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™ä½¿ç”¨è¯¥ sessionï¼‰

        Returns:
            åŒ…å«å®ä½“å…³è”çš„äº‹é¡¹åˆ—è¡¨
        """
        try:
            self.logger.info(f"å¼€å§‹ç»Ÿä¸€å¤„ç† {len(events)} ä¸ªäº‹é¡¹çš„å®ä½“å…³è”")

            # æ”¶é›†æ‰€æœ‰å®ä½“æ•°æ®ï¼ˆåŒ…æ‹¬ LLM æå–çš„ + é»˜è®¤å€¼å®ä½“ï¼‰
            # ä½¿ç”¨å­—å…¸å­˜å‚¨ï¼škey=entity_name, value=description
            all_entities_data = {}

            # 1ï¸âƒ£ å…ˆæ”¶é›† LLM æå–çš„å®ä½“
            for event in events:
                entities_data = event.extra_data.get("raw_entities", {})
                for entity_type, entity_names in entities_data.items():
                    if entity_type not in all_entities_data:
                        all_entities_data[entity_type] = {}  # æ”¹ä¸ºå­—å…¸

                    # å…¼å®¹æ–°æ—§æ ¼å¼
                    for entity_data in entity_names:
                        if isinstance(entity_data, dict):
                            name = entity_data.get("name")
                            description = entity_data.get("description", "")
                        else:
                            # æ—§æ ¼å¼ï¼šç›´æ¥æ˜¯å­—ç¬¦ä¸²
                            name = entity_data
                            description = ""

                        if name:
                            # å¦‚æœå·²å­˜åœ¨ä¸”æ²¡æœ‰æè¿°ï¼Œç”¨æ–°çš„æè¿°æ›´æ–°
                            if name not in all_entities_data[entity_type]:
                                all_entities_data[entity_type][name] = description
                            elif description and not all_entities_data[entity_type][name]:
                                all_entities_data[entity_type][name] = description

            # 2ï¸âƒ£ æ·»åŠ é…ç½®çš„é»˜è®¤å€¼å®ä½“åˆ°æ”¶é›†æ± 
            for entity_type_config in self.entity_types:
                constraints = entity_type_config.value_constraints or {}
                default_value = constraints.get('default')
                if default_value:
                    entity_type = entity_type_config.type
                    if entity_type not in all_entities_data:
                        all_entities_data[entity_type] = {}
                    # æ·»åŠ é»˜è®¤å€¼å®ä½“ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
                    if default_value not in all_entities_data[entity_type]:
                        all_entities_data[entity_type][default_value] = "ç³»ç»Ÿé»˜è®¤å€¼"
                        self.logger.debug(
                            f"ğŸ“Œ æ·»åŠ é»˜è®¤å€¼å®ä½“åˆ°æ”¶é›†æ± : {entity_type}={default_value}"
                        )

            # å®ä½“ç¼“å­˜ï¼Œé¿å…é‡å¤æŸ¥è¯¢
            # key: (entity_type, normalized_name), value: entity_id
            entity_id_map = {}

            # åˆ¤æ–­æ˜¯å¦éœ€è¦åˆ›å»ºæ–° session
            should_close_session = False
            if session is None:
                session = self.session_factory()
                session = await session.__aenter__()
                should_close_session = True

            try:
                # ç»Ÿä¸€åˆ›å»º/è·å–æ‰€æœ‰å®ä½“ï¼ˆä½¿ç”¨åŒä¸€ä¸ª sessionï¼‰
                for entity_type, entities_dict in all_entities_data.items():
                    entity_type_obj = self._get_entity_type_by_type(
                        entity_type)
                    if not entity_type_obj:
                        continue

                    for name, description in entities_dict.items():
                        normalized_name = self._normalize_entity_name(name)
                        cache_key = (entity_type, normalized_name)

                        # æ£€æŸ¥ç¼“å­˜
                        if cache_key in entity_id_map:
                            continue

                        # è·å–æˆ–åˆ›å»ºå®ä½“IDï¼ˆä¸ä¼ å…¥descriptionï¼‰
                        entity_id = await self._get_or_create_entity_with_session(
                            session, entity_type, name, normalized_name, entity_type_obj
                        )
                        # åœ¨ç¼“å­˜ä¸­åŒæ—¶å­˜å‚¨IDå’Œdescription
                        entity_id_map[cache_key] = (entity_id, description)

                # å¦‚æœåˆ›å»ºäº†æ–° sessionï¼Œéœ€è¦æäº¤å®ä½“çš„åˆ›å»º
                if should_close_session:
                    await session.commit()
                    self.logger.debug(f"å·²æäº¤ {len(entity_id_map)} ä¸ªå®ä½“åˆ°æ•°æ®åº“")

                # ğŸ“Œ é¢„å…ˆæ”¶é›†æ‰€æœ‰å¼ºåˆ¶æ¨¡å¼çš„é»˜è®¤å€¼ï¼ˆç”¨äºæ ‡è®°ï¼‰
                forced_defaults = {}  # {entity_type: default_value}
                for entity_type_config in self.entity_types:
                    constraints = entity_type_config.value_constraints or {}
                    default_value = constraints.get('default')
                    override_mode = constraints.get('override', False)
                    if default_value and override_mode:
                        forced_defaults[entity_type_config.type] = default_value

                # ä¸ºæ‰€æœ‰äº‹é¡¹å»ºç«‹å®ä½“å…³è”
                for event in events:
                    entities_data = event.extra_data.get("raw_entities", {})
                    event_associations = []
                    
                    # ğŸ†• ä½¿ç”¨å­—å…¸è·Ÿè¸ªæ¯ä¸ªå®ä½“IDåŠå…¶ä¿¡æ¯ï¼ˆé˜²æ­¢é‡å¤å…³è”ï¼‰
                    entity_map = {}  # {entity_id: {"name": str, "descriptions": [str], "weight": float, ...}}

                    # 3ï¸âƒ£ å»ºç«‹ LLM æå–çš„å®ä½“å…³è”
                    for entity_type, entity_names in entities_data.items():
                        entity_type_obj = self._get_entity_type_by_type(
                            entity_type)
                        if not entity_type_obj:
                            continue

                        for entity_data in entity_names:
                            # å…¼å®¹æ–°æ—§æ ¼å¼
                            if isinstance(entity_data, dict):
                                name = entity_data.get("name")
                                description = entity_data.get(
                                    "description", "")
                            else:
                                name = entity_data
                                description = ""

                            if not name:
                                continue

                            normalized_name = self._normalize_entity_name(name)
                            key = (entity_type, normalized_name)
                            if key in entity_id_map:
                                # ä»ç¼“å­˜è·å–entity_idå’Œdescription
                                entity_id, cached_description = entity_id_map[key]
                                
                                # ğŸ†• æ£€æŸ¥æ˜¯å¦å·²æ·»åŠ è¿‡è¿™ä¸ªå®ä½“
                                if entity_id not in entity_map:
                                    # é¦–æ¬¡æ·»åŠ 
                                    entity_map[entity_id] = {
                                        "name": name,
                                        "type": entity_type,
                                        "descriptions": [],
                                        "weight": float(entity_type_obj.weight),
                                        "is_forced_default": False
                                    }
                                
                                # æ”¶é›†æè¿°
                                if description and description not in entity_map[entity_id]["descriptions"]:
                                    entity_map[entity_id]["descriptions"].append(description)
                                if cached_description and cached_description not in entity_map[entity_id]["descriptions"]:
                                    entity_map[entity_id]["descriptions"].append(cached_description)
                                
                                # æ£€æŸ¥æ˜¯å¦æ˜¯å¼ºåˆ¶æ¨¡å¼çš„é»˜è®¤å€¼
                                if entity_type in forced_defaults and name == forced_defaults[entity_type]:
                                    entity_map[entity_id]["is_forced_default"] = True

                    # 4ï¸âƒ£ åº”ç”¨é»˜è®¤å€¼å®ä½“å…³è”é€»è¾‘
                    extracted_by_type = {}
                    for entity_type, entity_names in entities_data.items():
                        names = []
                        for e in entity_names:
                            name = e.get('name') if isinstance(e, dict) else e
                            if name:
                                names.append(name)
                        extracted_by_type[entity_type] = names

                    # æ£€æŸ¥æ¯ä¸ªå®ä½“ç±»å‹çš„é»˜è®¤å€¼é…ç½®
                    for entity_type_config in self.entity_types:
                        constraints = entity_type_config.value_constraints or {}
                        default_value = constraints.get('default')
                        override_mode = constraints.get('override', False)

                        if not default_value:
                            continue

                        entity_type = entity_type_config.type
                        entity_names_of_type = extracted_by_type.get(
                            entity_type, [])
                        has_default = default_value in entity_names_of_type

                        # åˆ¤æ–­æ˜¯å¦éœ€è¦æ·»åŠ é»˜è®¤å€¼å…³è”
                        should_add_default = False
                        if override_mode:
                            # å¼ºåˆ¶æ¨¡å¼ï¼šæ€»æ˜¯è¦æœ‰ï¼ˆä½†å¦‚æœLLMå·²æå–å°±ä¸é‡å¤ï¼‰
                            should_add_default = not has_default
                        else:
                            # è¡¥å……æ¨¡å¼ï¼šä»…å½“è¯¥ç±»å‹å®Œå…¨æ²¡æœ‰å®ä½“æ—¶è¡¥å……
                            should_add_default = len(entity_names_of_type) == 0

                        if should_add_default:
                            # ä»ç¼“å­˜è·å–é»˜è®¤å€¼å®ä½“ID
                            normalized_name = self._normalize_entity_name(
                                default_value)
                            key = (entity_type, normalized_name)
                            if key in entity_id_map:
                                entity_id, _ = entity_id_map[key]
                                
                                # ğŸ†• æ£€æŸ¥æ˜¯å¦å·²æ·»åŠ è¿‡è¿™ä¸ªå®ä½“
                                if entity_id not in entity_map:
                                    mode_desc = "å¼ºåˆ¶è¿½åŠ " if override_mode else "è‡ªåŠ¨è¡¥å……"
                                    
                                    entity_map[entity_id] = {
                                        "name": default_value,
                                        "type": entity_type,
                                        "descriptions": [f"ç³»ç»Ÿé»˜è®¤å€¼ï¼ˆ{mode_desc}ï¼‰"],
                                        "weight": float(entity_type_config.weight),
                                        "is_forced_default": False,
                                        "is_default": True,
                                        "mode": mode_desc
                                    }
                                    
                                    self.logger.debug(
                                        f"âœ… {mode_desc}é»˜è®¤å€¼å…³è”: {entity_type}={default_value}, "
                                        f"event_id={event.id[:8]}..."
                                    )
                                else:
                                    self.logger.debug(
                                        f"â­ï¸  è·³è¿‡é»˜è®¤å€¼ï¼ˆå·²å­˜åœ¨ï¼‰: {entity_type}={default_value}, "
                                        f"event_id={event.id[:8]}..."
                                    )

                    # ğŸ†• ä¸ºæ¯ä¸ªå”¯ä¸€çš„ entity_id åˆ›å»ºä¸€ä¸ªå…³è”ï¼ˆåˆå¹¶æè¿°ï¼‰
                    for entity_id, info in entity_map.items():
                        # åˆå¹¶æè¿°
                        if info.get("is_forced_default"):
                            final_description = "ç³»ç»Ÿé»˜è®¤å€¼ï¼ˆå¼ºåˆ¶å†™å…¥ï¼‰"
                        elif info.get("is_default"):
                            final_description = info["descriptions"][0] if info["descriptions"] else None
                        elif info["descriptions"]:
                            final_description = "ã€".join(info["descriptions"])
                        else:
                            final_description = None
                        
                        # åˆ›å»ºå…³è”
                        extra_data = {
                            "confidence": event.extra_data.get("quality_score", 0.8),
                        }
                        if info.get("is_forced_default"):
                            extra_data["is_forced_default"] = True
                        if info.get("is_default"):
                            extra_data["is_default"] = True
                            extra_data["mode"] = info.get("mode")
                        if len(info["descriptions"]) > 1:
                            extra_data["description_count"] = len(info["descriptions"])
                        
                        assoc = EventEntity(
                            id=str(uuid.uuid4()),
                            event_id=event.id,
                            entity_id=entity_id,
                            weight=info["weight"],
                            description=final_description,
                            extra_data=extra_data,
                        )
                        event_associations.append(assoc)
                        
                        # æ—¥å¿—ï¼šåˆå¹¶äº†å¤šä¸ªæè¿°
                        if len(info["descriptions"]) > 1:
                            self.logger.debug(
                                f"âœ… åˆå¹¶å®ä½“æè¿°: {info['name']} ({len(info['descriptions'])}ä¸ª) -> {final_description}"
                            )

                    event.event_associations = event_associations

                    # æ¸…ç†ä¸´æ—¶æ•°æ®
                    if "raw_entities" in event.extra_data:
                        del event.extra_data["raw_entities"]

                self.logger.info(f"å®Œæˆ {len(events)} ä¸ªäº‹é¡¹çš„å®ä½“å…³è”å¤„ç†")
                return events

            finally:
                if should_close_session:
                    await session.__aexit__(None, None, None)

        except Exception as e:
            self.logger.error(f"å®ä½“å…³è”å¤„ç†å¤±è´¥: {e}", exc_info=True)
            raise ExtractError(f"å®ä½“å…³è”å¤„ç†å¤±è´¥: {e}") from e

    async def _parse_extraction_result_without_entities(
        self, result: Dict[str, Any], sections: List[SourceChunk]
    ) -> List[SourceEvent]:
        """
        è§£æLLMæå–ç»“æœä¸ºSourceEventå¯¹è±¡ï¼ˆä¸å¤„ç†å®ä½“å…³è”ï¼‰

        Args:
            result: LLMè¿”å›çš„JSONç»“æœ
            sections: åŸå§‹ç‰‡æ®µåˆ—è¡¨ï¼ˆç”¨äºç”Ÿæˆå¼•ç”¨ï¼‰

        Returns:
            ä¸å«å®ä½“å…³è”çš„SourceEventå¯¹è±¡åˆ—è¡¨
        """
        events = []
        for event_data in result.get("events", []):
            # è§£æ LLM æ ‡æ³¨çš„å¼•ç”¨ï¼ˆç‰‡æ®µç¼–å·ï¼Œä»1å¼€å§‹ï¼‰
            referenced_indices = event_data.get("references", [])
            # å°†ç‰‡æ®µç¼–å·è½¬æ¢ä¸ºå®é™…çš„ section_id
            referenced_section_ids = []
            invalid_indices = []
            for idx in referenced_indices:
                if isinstance(idx, int) and 1 <= idx <= len(sections):  # éªŒè¯ç´¢å¼•æœ‰æ•ˆæ€§
                    section = sections[idx - 1]  # ç¼–å·ä»1å¼€å§‹ï¼Œç´¢å¼•ä»0å¼€å§‹
                    referenced_section_ids.append(section.id)
                else:
                    # è®°å½•æ— æ•ˆç´¢å¼•
                    invalid_indices.append(idx)

            # è®°å½•è­¦å‘Šï¼ˆå¦‚æœæœ‰æ— æ•ˆç´¢å¼•ï¼‰
            if invalid_indices:
                self.logger.warning(
                    f"äº‹é¡¹ '{event_data.get('title', 'æœªçŸ¥')}' åŒ…å«æ— æ•ˆçš„ç‰‡æ®µå¼•ç”¨ç´¢å¼•: {invalid_indices}",
                    extra={
                        "event_title": event_data.get("title"),
                        "invalid_indices": invalid_indices,
                        "total_sections": len(sections),
                    },
                )

            # ğŸ†• ==================== å®ä½“è½¬æ¢ã€å»é‡ä¸åˆå¹¶é€»è¾‘ï¼ˆæºå¤´å¤„ç†ï¼‰====================
            # 1. å°† LLM è¿”å›çš„æ•°ç»„æ ¼å¼è½¬æ¢ä¸ºæŒ‰ type åˆ†ç»„çš„å­—å…¸æ ¼å¼
            entities_from_llm = event_data.get("entities", [])
            entities_raw = {}

            # å¦‚æœ LLM è¿”å›çš„æ˜¯æ•°ç»„ï¼ˆschema å®šä¹‰çš„æ ¼å¼ï¼‰
            if isinstance(entities_from_llm, list):
                for entity_item in entities_from_llm:
                    if not isinstance(entity_item, dict):
                        continue
                    
                    entity_type = entity_item.get("type")
                    if not entity_type:
                        continue
                    
                    # æŒ‰ç±»å‹åˆ†ç»„
                    if entity_type not in entities_raw:
                        entities_raw[entity_type] = []
                    
                    entities_raw[entity_type].append({
                        "name": entity_item.get("name", ""),
                        "description": entity_item.get("description", "")  # ä¿ç•™ description
                    })
            # å…¼å®¹æ—§çš„å­—å…¸æ ¼å¼ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            elif isinstance(entities_from_llm, dict):
                entities_raw = entities_from_llm

            # 2. å¯¹æ¯ä¸ªç±»å‹å†…çš„å®ä½“å»é‡ï¼Œå¹¶æ™ºèƒ½åˆå¹¶ description
            entities_deduped = {}

            for entity_type, entity_list in entities_raw.items():
                if not entity_list:
                    entities_deduped[entity_type] = []
                    continue
                
                # ä½¿ç”¨å­—å…¸æ”¶é›†ï¼škey=normalized_name, value={"name": str, "descriptions": [str]}
                merged_entities = {}
                
                for entity_data in entity_list:
                    # å…¼å®¹æ ¼å¼ï¼šå­—å…¸æˆ–å­—ç¬¦ä¸²
                    if isinstance(entity_data, dict):
                        name = entity_data.get("name", "").strip()
                        description = entity_data.get("description", "").strip()
                    else:
                        name = str(entity_data).strip()
                        description = ""
                    
                    if not name:
                        continue
                    
                    # è§„èŒƒåŒ–åç§°ç”¨äºå»é‡
                    normalized_name = name.lower().strip()
                    
                    # ç¬¬ä¸€æ¬¡é‡åˆ°è¿™ä¸ªå®ä½“
                    if normalized_name not in merged_entities:
                        merged_entities[normalized_name] = {
                            "name": name,  # ä¿ç•™åŸå§‹åç§°ï¼ˆç¬¬ä¸€æ¬¡å‡ºç°çš„ï¼‰
                            "descriptions": []
                        }
                    
                    # æ”¶é›†æè¿°ï¼ˆå»é‡ã€å»ç©ºï¼‰
                    if description:
                        existing_descs = merged_entities[normalized_name]["descriptions"]
                        if description not in existing_descs:
                            existing_descs.append(description)
                
                # è½¬æ¢å›åˆ—è¡¨æ ¼å¼ï¼Œåˆå¹¶æè¿°
                deduped_list = []
                for entity_info in merged_entities.values():
                    # ç”¨ä¸­æ–‡é¡¿å·è¿æ¥å¤šä¸ªæè¿°
                    final_desc = "ã€".join(entity_info["descriptions"]) if entity_info["descriptions"] else ""
                    
                    deduped_list.append({
                        "name": entity_info["name"],
                        "description": final_desc  # åˆå¹¶åçš„æè¿°
                    })
                    
                    if len(entity_info["descriptions"]) > 1:
                        self.logger.debug(
                            f"âœ… åˆå¹¶é‡å¤å®ä½“æè¿° [{entity_type}] {entity_info['name']}: "
                            f"{len(entity_info['descriptions'])}ä¸ª -> {final_desc}"
                        )
                
                entities_deduped[entity_type] = deduped_list
            # =================================================================

            # ç¡®å®šä¸»è¦å¼•ç”¨çš„ chunkï¼ˆå–ç¬¬ä¸€ä¸ªè¢«å¼•ç”¨çš„ chunkï¼‰
            primary_chunk = None
            if referenced_section_ids:
                # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªè¢«å¼•ç”¨çš„ section å¯¹åº”çš„ chunk
                for section in sections:
                    if section.id == referenced_section_ids[0]:
                        primary_chunk = section
                        break
                if not primary_chunk:
                    primary_chunk = sections[0]  # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œé»˜è®¤ä½¿ç”¨ç¬¬ä¸€ä¸ª chunk
            else:
                primary_chunk = sections[0] if sections else None

            # ğŸ†• æ ¹æ®æ¥æºç±»å‹è®¾ç½®æ—¶é—´
            # æ³¨æ„ï¼šåœ¨ processor ä¸­ï¼Œäº‹é¡¹çš„ references ç›´æ¥ç»§æ‰¿è‡ª primary_chunk.references
            # æ‰€ä»¥ç”¨ primary_chunk.references æ¥æŸ¥è¯¢æ—¶é—´æ˜¯æ­£ç¡®çš„
            from datetime import datetime
            from sag.db import ChatMessage
            from sqlalchemy import select
            
            start_time = None
            end_time = None
            event_references = primary_chunk.references if primary_chunk else None
            
            if primary_chunk:
                if primary_chunk.source_type == "ARTICLE":
                    # æ–‡æ¡£ç±»å‹ï¼šä½¿ç”¨å½“å‰æ—¶é—´
                    current_time = datetime.now()
                    start_time = current_time
                    end_time = current_time
                    
                elif primary_chunk.source_type == "CHAT":
                    # ä¼šè¯ç±»å‹ï¼šä»å¼•ç”¨çš„æ¶ˆæ¯ä¸­è·å–æ—¶é—´èŒƒå›´
                    # ä½¿ç”¨ primary_chunk.referencesï¼ˆå› ä¸ºäº‹é¡¹ä¼šç»§æ‰¿è¿™ä¸ªï¼‰
                    if event_references and isinstance(event_references, list):
                        async with self.session_factory() as session:
                            result_msgs = await session.execute(
                                select(ChatMessage)
                                .where(ChatMessage.id.in_(event_references))
                                .order_by(ChatMessage.timestamp)
                            )
                            messages = list(result_msgs.scalars().all())
                            
                            if messages:
                                start_time = messages[0].timestamp  # æœ€æ—©æ—¶é—´
                                end_time = messages[-1].timestamp  # æœ€æ™šæ—¶é—´
                                self.logger.debug(
                                    f"ä¼šè¯äº‹é¡¹æ—¶é—´: {start_time} ~ {end_time} "
                                    f"(å…±{len(messages)}æ¡æ¶ˆæ¯)"
                                )

            # åˆ›å»ºäº‹é¡¹å¯¹è±¡
            source_type_value = primary_chunk.source_type if primary_chunk else "ARTICLE"
            event = SourceEvent(
                id=str(uuid.uuid4()),
                source_config_id=self.config.source_config_id,
                source_type=source_type_value,
                source_id=primary_chunk.source_id if primary_chunk else sections[0].source_id,
                article_id=sections[0].article_id if primary_chunk and primary_chunk.source_type == "ARTICLE" else None,
                conversation_id=primary_chunk.conversation_id if primary_chunk and primary_chunk.source_type == "CHAT" else None,
                title=event_data["title"],
                summary=event_data.get("summary") or "",
                content=event_data["content"],
                category=event_data.get("category") or "",  # ç‹¬ç«‹å­—æ®µï¼Œç¡®ä¿Noneè½¬ä¸ºç©ºå­—ç¬¦ä¸²
                # ä¸šåŠ¡å­—æ®µï¼ˆå…¼å®¹ä¸»ç³»ç»Ÿï¼‰- typeä¸source_typeä¿æŒä¸€è‡´
                type=source_type_value,
                priority="UNKNOWN",  # é»˜è®¤å€¼
                status="UNKNOWN",  # é»˜è®¤å€¼
                rank=None,  # ç”±ä¸Šå±‚ EventExtractor ç»Ÿä¸€åˆ†é…å…¨å±€ rank
                start_time=start_time,
                end_time=end_time,
                references=referenced_section_ids,  # âœ… ä¿®å¤ï¼šä½¿ç”¨LLMç²¾ç¡®æ ‡æ³¨çš„å¼•ç”¨
                chunk_id=primary_chunk.id if primary_chunk else None,
                extra_data={
                    "quality_score": event_data.get("quality_score", 0.8),
                    "batch_size": len(sections),
                    # ä¿å­˜å»é‡åçš„å®ä½“æ•°æ®ï¼Œç”¨äºç¬¬äºŒé˜¶æ®µå¤„ç†
                    "raw_entities": entities_deduped,
                },
            )

            events.append(event)

        return events

    async def initialize(self) -> None:
        """
        åˆå§‹åŒ–å¤„ç†å™¨ï¼ˆåŠ è½½å®ä½“ç±»å‹é…ç½®ï¼‰

        å¿…é¡»åœ¨ä½¿ç”¨å¤„ç†å™¨ä¹‹å‰è°ƒç”¨æ­¤æ–¹æ³•
        """
        await self._load_entity_types()

    async def _load_entity_types(self) -> None:
        """
        ä»æ•°æ®åº“åŠ è½½å®ä½“ç±»å‹é…ç½®

        åŠ è½½è§„åˆ™ï¼ˆæŒ‰ä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼‰ï¼š
        1. æ–‡æ¡£çº§åˆ«ï¼ˆscope='article', article_id=å½“å‰æ–‡æ¡£ï¼‰
        2. ä¿¡æ¯æºçº§åˆ«ï¼ˆscope='source', source_config_id=å½“å‰ä¿¡æ¯æºï¼‰
        3. å…¨å±€è‡ªå®šä¹‰ï¼ˆscope='global', source_config_id IS NULL, is_default=FALSEï¼‰
        4. ç³»ç»Ÿé»˜è®¤ï¼ˆsource_config_id IS NULL, is_default=TRUEï¼‰

        æ³¨æ„ï¼šåŒä¸€ä¸ª type åªå–ä¼˜å…ˆçº§æœ€é«˜çš„é…ç½®
        """
        async with self.session_factory() as session:
            # æŸ¥è¯¢æ¡ä»¶åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
            conditions = []

            # 1. æ–‡æ¡£çº§åˆ«ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
            if self.config.article_id:
                conditions.append(
                    (DBEntityType.scope == 'article')
                    & (DBEntityType.article_id == self.config.article_id)
                    & DBEntityType.is_active
                )

            # 2. ä¿¡æ¯æºçº§åˆ«
            if self.config.source_config_id:
                conditions.append(
                    (DBEntityType.scope == 'source')
                    & (DBEntityType.source_config_id == self.config.source_config_id)
                    & DBEntityType.is_active
                )

            # 3. å…¨å±€è‡ªå®šä¹‰ç±»å‹
            conditions.append(
                (DBEntityType.scope == 'global')
                & DBEntityType.source_config_id.is_(None)
                & (DBEntityType.is_default == False)
                & DBEntityType.is_active
            )

            # 4. ç³»ç»Ÿé»˜è®¤ç±»å‹
            conditions.append(
                DBEntityType.source_config_id.is_(None)
                & DBEntityType.is_default
                & DBEntityType.is_active
                    )

            # æŸ¥è¯¢æ‰€æœ‰åŒ¹é…çš„å®ä½“ç±»å‹
            result = await session.execute(
                select(DBEntityType)
                .where(or_(*conditions))
                .order_by(DBEntityType.weight.desc())
            )
            all_entity_types = list(result.scalars().all())

            # å»é‡ï¼šåŒä¸€ä¸ª type åªä¿ç•™ä¼˜å…ˆçº§æœ€é«˜çš„
            # ä¼˜å…ˆçº§ï¼šæ–‡æ¡£ > ä¿¡æ¯æº > å…¨å±€ > é»˜è®¤
            type_priority_map = {}
            for et in all_entity_types:
                if et.type not in type_priority_map:
                    # ç¬¬ä¸€æ¬¡å‡ºç°è¯¥ç±»å‹ï¼Œè®°å½•ä¸‹æ¥
                    type_priority_map[et.type] = et
                else:
                    # è¯¥ç±»å‹å·²å­˜åœ¨ï¼Œæ¯”è¾ƒä¼˜å…ˆçº§
                    existing = type_priority_map[et.type]

                    # ç¡®å®šä¼˜å…ˆçº§å¾—åˆ†ï¼ˆæ•°å€¼è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
                    def get_priority_score(entity_type):
                        if entity_type.scope == 'article' and entity_type.article_id == self.config.article_id:
                            return 1  # æ–‡æ¡£çº§åˆ«
                        elif entity_type.scope == 'source' and entity_type.source_config_id == self.config.source_config_id:
                            return 2  # ä¿¡æ¯æºçº§åˆ«
                        elif entity_type.scope == 'global' and not entity_type.is_default:
                            return 3  # å…¨å±€è‡ªå®šä¹‰
                        elif entity_type.is_default:
                            return 4  # ç³»ç»Ÿé»˜è®¤
                        else:
                            return 5  # å…¶ä»–ï¼ˆä¸åº”è¯¥å‡ºç°ï¼‰

                    if get_priority_score(et) < get_priority_score(existing):
                        type_priority_map[et.type] = et

            self.entity_types = list(type_priority_map.values())

        self.logger.info(
            f"åŠ è½½äº† {len(self.entity_types)} ä¸ªå®ä½“ç±»å‹é…ç½®",
            extra={
                "article_id": self.config.article_id,
                "source_config_id": self.config.source_config_id,
                "entity_types": [et.type for et in self.entity_types],
            },
        )

        # ğŸ” è°ƒè¯•ï¼šè¾“å‡ºæ¯ä¸ªå®ä½“ç±»å‹çš„è¯¦ç»†ä¿¡æ¯
        for et in self.entity_types:
            scope_desc = f"{et.scope}"
            if et.scope == 'article':
                scope_desc += f"(article_id={et.article_id[:8]}...)"
            elif et.scope == 'source':
                scope_desc += f"(source_config_id={et.source_config_id[:8] if et.source_config_id else 'None'}...)"
            elif et.is_default:
                scope_desc += "(default)"

            self.logger.info(
                f"ğŸ” å®ä½“ç±»å‹ [{et.type}]: "
                f"name={et.name}, scope={scope_desc}, "
                f"is_active={et.is_active}, is_default={et.is_default}, "
                f"value_constraints={et.value_constraints}"
            )

    def _build_context(self, sections: List[SourceChunk]) -> str:
        """
        æ„å»ºæ¥æºç‰‡æ®µä¸Šä¸‹æ–‡

        Args:
            sections: æ¥æºç‰‡æ®µåˆ—è¡¨

        Returns:
            æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡æ–‡æœ¬
        """
        context_parts = []

        for i, section in enumerate(sections, 1):
            context_parts.append(f"## ç‰‡æ®µ {i}: {section.heading}")
            context_parts.append(f"{section.content}")
            context_parts.append("")  # ç©ºè¡Œåˆ†éš”

        return "\n".join(context_parts)

    def _build_prompt(self, context: str) -> str:
        """
        æ„å»ºæç¤ºè¯

        Args:
            context: ä¸Šä¸‹æ–‡æ–‡æœ¬

        Returns:
            å®Œæ•´çš„æç¤ºè¯
        """
        # è·å–å®ä½“ç±»å‹è¯´æ˜
        entity_types_desc = self._get_entity_types_description()

        # ä½¿ç”¨PromptManageræ¸²æŸ“æ¨¡æ¿
        try:
            prompt = self.prompt_manager.render(
                "event_extraction",
                context=context,
                background=self.config.background or "",
                entity_types=entity_types_desc,
            )
        except Exception as e:
            # å¦‚æœæ¨¡æ¿ä¸å­˜åœ¨ï¼Œä½¿ç”¨å†…ç½®æ¨¡æ¿
            self.logger.warning(f"æç¤ºè¯æ¨¡æ¿ä¸å­˜åœ¨ï¼Œä½¿ç”¨å†…ç½®æ¨¡æ¿: {e}")
            prompt = self._build_default_prompt(context, entity_types_desc)

        return prompt

    def _build_default_prompt(self, context: str, entity_types_desc: str) -> str:
        """æ„å»ºé»˜è®¤æç¤ºè¯ï¼ˆå½“YAMLæ¨¡æ¿ä¸å­˜åœ¨æ—¶ï¼‰"""
        background_section = (
            f"\n## èƒŒæ™¯ä¿¡æ¯\n{self.config.background}\n" if self.config.background else ""
        )

        return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¿¡æ¯æå–åŠ©æ‰‹ã€‚è¯·ä»ä»¥ä¸‹æ–‡ç« ç‰‡æ®µä¸­æå–äº‹é¡¹ï¼ˆEventsï¼‰å’Œå®ä½“ï¼ˆEntitiesï¼‰ã€‚
            {background_section}
            ## æå–è§„åˆ™

            ### äº‹é¡¹ï¼ˆEventï¼‰
            - ç‹¬ç«‹çš„ã€å®Œæ•´çš„ä¿¡æ¯å•å…ƒ
            - å¯ä»¥æ˜¯ï¼šäº‹ä»¶ã€ä¼šè®®ã€å†³ç­–ã€å‘ç°ã€ç»“è®ºã€ä»»åŠ¡ç­‰
            - æ¯ä¸ªäº‹é¡¹å¿…é¡»åŒ…å«æ ‡é¢˜ã€å†…å®¹
            - **é‡è¦**ï¼šå¿…é¡»æ ‡æ³¨è¯¥äº‹é¡¹å¼•ç”¨äº†å“ªäº›ç‰‡æ®µï¼ˆå¡«å†™ç‰‡æ®µç¼–å·ï¼Œå¦‚ [1, 2]ï¼‰
            - ä¸ºæ¯ä¸ªäº‹é¡¹è¯„ä¼°è´¨é‡åˆ†æ•°ï¼ˆ0-1ï¼Œè¶Šé«˜è¡¨ç¤ºä¿¡æ¯è¶Šå®Œæ•´ã€è¶Šæœ‰ä»·å€¼ï¼‰

            ### å®ä½“ï¼ˆEntityï¼‰
            æŒ‰ä»¥ä¸‹ç»´åº¦æå–å®ä½“ï¼š

            {entity_types_desc}

            ## æ–‡ç« ç‰‡æ®µ

            {context}

            ## è¾“å‡ºè¦æ±‚
            ä¸¥æ ¼æŒ‰ç…§JSON Schemaæ ¼å¼è¿”å›ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡æœ¬ã€‚
        """

    def _get_entity_types_description(self) -> str:
        """è·å–å®ä½“ç±»å‹è¯´æ˜"""
        lines = []

        for entity_type in self.entity_types:
            lines.append(
                f"- **{entity_type.type}** ({entity_type.name}): {entity_type.description}"
            )

        return "\n".join(lines)

    def _build_extraction_schema(self) -> Dict[str, Any]:
        """
        æ„å»ºåŠ¨æ€JSON Schemaï¼ˆåŸºäºæ•°æ®åº“ä¸­çš„å®ä½“ç±»å‹é…ç½®ï¼‰

        Returns:
            JSON Schemaå­—å…¸
        """
        # åŠ¨æ€æ„å»ºå®ä½“ç±»å‹properties
        entity_properties = {}
        for entity_type in self.entity_types:
            entity_properties[entity_type.type] = {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "name": {"type": "string", "description": "å®ä½“åç§°"},
                        "description": {"type": "string", "description": "å®ä½“æè¿°ï¼ˆå¯é€‰ï¼Œå¦‚èŒä½ã€è§’è‰²ã€å®šä¹‰ç­‰ï¼‰"}
                    },
                    "required": ["name"]
                },
                "description": entity_type.description or entity_type.name,
            }

        # äº‹é¡¹å¿…éœ€å­—æ®µ
        event_required = ["title", "content", "references", "entities"]

        return {
            "type": "object",
            "properties": {
                "events": {
                    "type": "array",
                    "description": "æå–çš„äº‹é¡¹åˆ—è¡¨",
                    "items": {
                        "type": "object",
                        "properties": {
                            "title": {"type": "string", "description": "äº‹é¡¹æ ‡é¢˜"},
                            "summary": {"type": "string", "description": "äº‹é¡¹æ‘˜è¦"},
                            "content": {"type": "string", "description": "äº‹é¡¹è¯¦ç»†å†…å®¹"},
                            "category": {"type": "string", "description": "äº‹é¡¹åˆ†ç±»ï¼ˆå¯é€‰ï¼Œå¦‚ï¼šæŠ€æœ¯/äº§å“/å¸‚åœº/ç ”ç©¶/ç®¡ç†ç­‰ï¼‰"},
                            "references": {
                                "type": "array",
                                "items": {"type": "integer"},
                                "description": "è¯¥äº‹é¡¹å¼•ç”¨çš„ç‰‡æ®µç¼–å·åˆ—è¡¨ï¼ˆä»1å¼€å§‹ï¼Œå¦‚ [1, 2]ï¼‰",
                            },
                            "entities": {
                                "type": "object",
                                "description": "å®ä½“å­—å…¸",
                                "properties": entity_properties,
                            },
                        },
                        "required": event_required,
                    },
                }
            },
            "required": ["events"],
        }

    async def _parse_extraction_result(
        self, result: Dict[str, Any], sections: List[SourceChunk]
    ) -> List[SourceEvent]:
        """
        è§£æLLMæå–ç»“æœä¸ºSourceEventå¯¹è±¡

        Args:
            result: LLMè¿”å›çš„JSONç»“æœ
            sections: åŸå§‹ç‰‡æ®µåˆ—è¡¨ï¼ˆç”¨äºç”Ÿæˆå¼•ç”¨ï¼‰

        Returns:
            SourceEventå¯¹è±¡åˆ—è¡¨
        """
        events = []

        for event_data in result.get("events", []):
            # è§£æ LLM æ ‡æ³¨çš„å¼•ç”¨ï¼ˆç‰‡æ®µç¼–å·ï¼Œä»1å¼€å§‹ï¼‰
            referenced_indices = event_data.get("references", [])

            # å°†ç‰‡æ®µç¼–å·è½¬æ¢ä¸ºå®é™…çš„ section_id
            referenced_section_ids = []
            invalid_indices = []

            for idx in referenced_indices:
                if isinstance(idx, int) and 1 <= idx <= len(sections):  # éªŒè¯ç´¢å¼•æœ‰æ•ˆæ€§
                    section = sections[idx - 1]  # ç¼–å·ä»1å¼€å§‹ï¼Œç´¢å¼•ä»0å¼€å§‹
                    referenced_section_ids.append(section.id)
                else:
                    # è®°å½•æ— æ•ˆç´¢å¼•
                    invalid_indices.append(idx)

            # è®°å½•è­¦å‘Šï¼ˆå¦‚æœæœ‰æ— æ•ˆç´¢å¼•ï¼‰
            if invalid_indices:
                self.logger.warning(
                    f"äº‹é¡¹ '{event_data.get('title', 'æœªçŸ¥')}' åŒ…å«æ— æ•ˆçš„ç‰‡æ®µå¼•ç”¨ç´¢å¼•: {invalid_indices}",
                    extra={
                        "event_title": event_data.get("title"),
                        "invalid_indices": invalid_indices,
                        "total_sections": len(sections),
                    },
                )

            # ç¡®å®šä¸»è¦å¼•ç”¨çš„ chunkï¼ˆå–ç¬¬ä¸€ä¸ªè¢«å¼•ç”¨çš„ chunkï¼‰
            primary_chunk = None
            if referenced_section_ids:
                # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªè¢«å¼•ç”¨çš„ section å¯¹åº”çš„ chunk
                for section in sections:
                    if section.id == referenced_section_ids[0]:
                        primary_chunk = section
                        break
                if not primary_chunk:
                    primary_chunk = sections[0]  # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œé»˜è®¤ä½¿ç”¨ç¬¬ä¸€ä¸ª chunk
            else:
                primary_chunk = sections[0] if sections else None

            # ğŸ†• æ ¹æ®æ¥æºç±»å‹è®¾ç½®æ—¶é—´
            from datetime import datetime
            from sag.db import ChatMessage
            from sqlalchemy import select
            
            start_time = None
            end_time = None
            event_references = primary_chunk.references if primary_chunk else None
            
            if primary_chunk:
                if primary_chunk.source_type == "ARTICLE":
                    # æ–‡æ¡£ç±»å‹ï¼šä½¿ç”¨å½“å‰æ—¶é—´
                    current_time = datetime.now()
                    start_time = current_time
                    end_time = current_time
                    
                elif primary_chunk.source_type == "CHAT":
                    # ä¼šè¯ç±»å‹ï¼šä»å¼•ç”¨çš„æ¶ˆæ¯ä¸­è·å–æ—¶é—´èŒƒå›´
                    # ä½¿ç”¨ primary_chunk.referencesï¼ˆå› ä¸ºäº‹é¡¹ä¼šç»§æ‰¿è¿™ä¸ªï¼‰
                    if event_references and isinstance(event_references, list):
                        async with self.session_factory() as session:
                            result_msgs = await session.execute(
                                select(ChatMessage)
                                .where(ChatMessage.id.in_(event_references))
                                .order_by(ChatMessage.timestamp)
                            )
                            messages = list(result_msgs.scalars().all())
                            
                            if messages:
                                start_time = messages[0].timestamp
                                end_time = messages[-1].timestamp
            
            # åˆ›å»ºäº‹é¡¹å¯¹è±¡
            # æ³¨æ„ï¼šsections åˆ—è¡¨å·²åœ¨æ–¹æ³•å¼€å§‹æ—¶éªŒè¯ä¸ºéç©º
            source_type_value = primary_chunk.source_type if primary_chunk else "ARTICLE"
            event = SourceEvent(
                id=str(uuid.uuid4()),
                source_config_id=self.config.source_config_id,
                source_type=source_type_value,  # ğŸ†•
                source_id=primary_chunk.source_id if primary_chunk else sections[0].source_id,  # ğŸ†•
                article_id=sections[0].article_id if primary_chunk and primary_chunk.source_type == "ARTICLE" else None,  # ğŸ†• ä¿®æ”¹
                conversation_id=primary_chunk.conversation_id if primary_chunk and primary_chunk.source_type == "CHAT" else None,  # ğŸ†•
                title=event_data["title"],
                summary=event_data.get("summary") or "",
                content=event_data["content"],
                category=event_data.get("category") or "",  # ç‹¬ç«‹å­—æ®µï¼Œç¡®ä¿Noneè½¬ä¸ºç©ºå­—ç¬¦ä¸²
                # ä¸šåŠ¡å­—æ®µï¼ˆå…¼å®¹ä¸»ç³»ç»Ÿï¼‰- typeä¸source_typeä¿æŒä¸€è‡´
                type=source_type_value,
                priority="UNKNOWN",  # é»˜è®¤å€¼
                status="UNKNOWN",  # é»˜è®¤å€¼
                rank=None,  # ç”±ä¸Šå±‚ EventExtractor ç»Ÿä¸€åˆ†é…å…¨å±€ rankï¼Œç¡®ä¿åŒä¸€æ–‡ç« å†…äº‹é¡¹æŒ‰é¡ºåºæ’åˆ—
                start_time=start_time,  # ğŸ†•
                end_time=end_time,  # ğŸ†•
                # ä½¿ç”¨ references å­—æ®µå­˜å‚¨ AI æ ‡æ³¨çš„å¼•ç”¨ç‰‡æ®µï¼ˆç²¾ç¡®å¼•ç”¨ï¼‰
                references=referenced_section_ids,  # âœ… ä¿®å¤ï¼šä½¿ç”¨LLMç²¾ç¡®æ ‡æ³¨çš„å¼•ç”¨
                chunk_id=primary_chunk.id if primary_chunk else None,
                extra_data={
                    "quality_score": event_data.get("quality_score", 0.8),
                    "batch_size": len(sections),
                    # categoryä¸å†å­˜å‚¨åœ¨extra_dataä¸­
                },
            )

            # è§£æå®ä½“
            entities_data = event_data.get("entities", {})
            event_associations = []

            # å¤„ç†æ¯ç§ç±»å‹çš„å®ä½“
            for entity_type, entity_names in entities_data.items():
                if not entity_names:
                    continue

                # æŸ¥æ‰¾å¯¹åº”çš„å®ä½“ç±»å‹å®šä¹‰
                entity_type_obj = self._get_entity_type_by_type(entity_type)
                if not entity_type_obj:
                    self.logger.warning(
                        f"æœªæ‰¾åˆ°å®ä½“ç±»å‹ '{entity_type}'ï¼Œè·³è¿‡è¯¥ç±»å‹çš„å®ä½“æå–",
                        extra={"entity_type": entity_type,
                               "event_title": event_data.get("title")},
                    )
                    continue

                for entity_data in entity_names:
                    # å…¼å®¹æ–°æ—§æ ¼å¼ï¼šå­—ç¬¦ä¸²æˆ–å¯¹è±¡
                    if isinstance(entity_data, dict):
                        name = entity_data.get("name")
                        description = entity_data.get("description", "")
                    else:
                        # æ—§æ ¼å¼ï¼šç›´æ¥æ˜¯å­—ç¬¦ä¸²
                        name = entity_data
                        description = ""

                    if not name:
                        continue

                    # è·å–æˆ–åˆ›å»ºå®ä½“IDï¼ˆä¸å†ä¼ é€’descriptionï¼‰
                    entity_id = await self._get_or_create_entity(
                        entity_type, name, entity_type_obj
                    )

                    # åˆ›å»ºå…³è”å¯¹è±¡ï¼ˆdescriptionä¿å­˜åˆ°ä¸­é—´è¡¨ï¼‰
                    assoc = EventEntity(
                        id=str(uuid.uuid4()),
                        event_id=event.id,
                        entity_id=entity_id,
                        weight=float(entity_type_obj.weight),
                        description=description or None,  # ä¿å­˜åˆ°ä¸­é—´è¡¨
                        extra_data={"confidence": event_data.get(
                            "quality_score", 0.8)},
                    )

                    # ç»‘å®šå…³ç³»
                    event_associations.append(assoc)

            event.event_associations = event_associations
            events.append(event)

        return events

    async def _get_or_create_entity(
        self, entity_type: str, entity_name: str, entity_type_obj: DBEntityType
    ) -> str:
        """
        è·å–æˆ–åˆ›å»ºå®ä½“çš„IDï¼ˆä½¿ç”¨æ–° sessionï¼‰

        å…ˆæŸ¥è¯¢æ•°æ®åº“æ˜¯å¦å­˜åœ¨ç›¸åŒ (source_config_id, type, normalized_name) çš„å®ä½“ï¼Œ
        å¦‚æœå­˜åœ¨åˆ™è¿”å›å…¶IDï¼Œå¦åˆ™åˆ›å»ºæ–°å®ä½“å¹¶è¿”å›æ–°IDã€‚

        Args:
            entity_type: å®ä½“ç±»å‹æ ‡è¯†ç¬¦
            entity_name: å®ä½“åŸå§‹åç§°
            entity_type_obj: å®ä½“ç±»å‹å¯¹è±¡

        Returns:
            å®ä½“ID
        """
        normalized_name = self._normalize_entity_name(entity_name)

        async with self.session_factory() as session:
            return await self._get_or_create_entity_with_session(
                session, entity_type, entity_name, normalized_name, entity_type_obj
            )

    async def _get_or_create_entity_with_session(
        self,
        session,
        entity_type: str,
        entity_name: str,
        normalized_name: str,
        entity_type_obj: DBEntityType,
    ) -> str:
        """
        è·å–æˆ–åˆ›å»ºå®ä½“çš„IDï¼ˆä½¿ç”¨å·²æœ‰ sessionï¼‰

        å…ˆæŸ¥è¯¢æ•°æ®åº“æ˜¯å¦å­˜åœ¨ç›¸åŒ (source_config_id, type, normalized_name) çš„å®ä½“ï¼Œ
        å¦‚æœå­˜åœ¨åˆ™è¿”å›å…¶IDï¼Œå¦åˆ™åˆ›å»ºæ–°å®ä½“å¹¶è¿”å›æ–°IDã€‚

        Args:
            session: æ•°æ®åº“ session
            entity_type: å®ä½“ç±»å‹æ ‡è¯†ç¬¦
            entity_name: å®ä½“åŸå§‹åç§°
            normalized_name: æ ‡å‡†åŒ–çš„å®ä½“åç§°
            entity_type_obj: å®ä½“ç±»å‹å¯¹è±¡

        Returns:
            å®ä½“ID
        """
        # æŸ¥è¯¢å·²å­˜åœ¨çš„å®ä½“
        result = await session.execute(
            select(Entity)
            .where(Entity.source_config_id == self.config.source_config_id)
            .where(Entity.type == entity_type)
            .where(Entity.normalized_name == normalized_name)
        )
        existing_entity = result.scalar_one_or_none()

        if existing_entity:
            self.logger.debug(
                f"å®ä½“å·²å­˜åœ¨ï¼š{entity_name} -> {existing_entity.name} (ID: {existing_entity.id})"
            )
            return existing_entity.id

        # åˆ›å»ºæ–°å®ä½“ï¼ˆä¸ä¿å­˜descriptionï¼‰
        new_entity = Entity(
            id=str(uuid.uuid4()),
            source_config_id=self.config.source_config_id,
            entity_type_id=entity_type_obj.id,
            type=entity_type,
            name=entity_name,
            normalized_name=normalized_name,
            description=None,  # ä¸å†ä¿å­˜descriptionåˆ°Entityè¡¨
            extra_data={},
        )

        # ğŸ†• è§£æç±»å‹åŒ–å€¼
        try:
            value_constraints = entity_type_obj.value_constraints if hasattr(
                entity_type_obj, 'value_constraints') else None
            entity_type_category = entity_type_obj.type if hasattr(
                entity_type_obj, 'type') else None
            typed_fields = self.parser.parse_to_typed_fields(
                entity_name,
                entity_type=entity_type,
                entity_type_category=entity_type_category,  # ğŸ†• ä¼ é€’å±æ€§ç±»å‹ï¼ˆtime/person/locationç­‰ï¼‰
                value_constraints=value_constraints
            )

            # å¡«å……ç±»å‹åŒ–å­—æ®µ
            if typed_fields:
                new_entity.value_type = typed_fields.get("value_type")
                new_entity.value_raw = typed_fields.get("value_raw")
                new_entity.int_value = typed_fields.get("int_value")
                new_entity.float_value = typed_fields.get("float_value")
                new_entity.datetime_value = typed_fields.get("datetime_value")
                new_entity.bool_value = typed_fields.get("bool_value")
                new_entity.enum_value = typed_fields.get("enum_value")
                new_entity.value_unit = typed_fields.get("value_unit")
                new_entity.value_confidence = typed_fields.get(
                    "value_confidence")

                self.logger.debug(
                    f"âœ… è§£æå®ä½“å€¼: {entity_name} -> {typed_fields.get('value_type')} = {typed_fields.get('int_value') or typed_fields.get('float_value') or typed_fields.get('datetime_value') or typed_fields.get('bool_value') or typed_fields.get('enum_value')}"
                )
        except Exception as e:
            # è§£æå¤±è´¥ä¸å½±å“å®ä½“åˆ›å»º
            self.logger.warning(f"âš ï¸ å®ä½“å€¼è§£æå¤±è´¥: {entity_name}, error={e}")

        # æ·»åŠ åˆ° sessionï¼ˆä½†ä¸ç«‹å³æäº¤ï¼‰
        session.add(new_entity)
        await session.flush()  # flush ä»¥è·å– IDï¼Œä½†ä¸æäº¤äº‹åŠ¡

        self.logger.debug(f"åˆ›å»ºæ–°å®ä½“ï¼š{entity_name} (ID: {new_entity.id})")
        return new_entity.id

    def _normalize_entity_name(self, name: str) -> str:
        """
        æ ‡å‡†åŒ–å®ä½“åç§°

        Args:
            name: åŸå§‹åç§°ï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å…¶ä»–ç±»å‹ï¼Œå¦‚æ•´æ•°ï¼‰

        Returns:
            æ ‡å‡†åŒ–åçš„åç§°
        """
        import re

        # å…ˆè½¬ä¸ºå­—ç¬¦ä¸²ï¼Œç¡®ä¿èƒ½å¤„ç†éå­—ç¬¦ä¸²è¾“å…¥ï¼ˆå¦‚ LLM æå–çš„æ•°å­—å®ä½“ï¼‰
        name_str = str(name)

        # å»é™¤é¦–å°¾ç©ºæ ¼å¹¶è½¬å°å†™
        normalized = name_str.strip().lower()

        # å»é™¤å¤šä½™çš„ç©ºæ ¼ï¼ˆå¤šä¸ªç©ºæ ¼åˆå¹¶ä¸ºä¸€ä¸ªï¼‰
        normalized = re.sub(r"\s+", " ", normalized)

        # å»é™¤å¸¸è§çš„æ ‡ç‚¹ç¬¦å·ï¼ˆä¿ç•™ä¸­æ–‡æ ‡ç‚¹ï¼‰
        normalized = re.sub(r"[^\w\s\u4e00-\u9fff]", "", normalized)

        return normalized.strip()

    def _get_entity_type_by_type(self, entity_type: str) -> Optional[DBEntityType]:
        """
        æ ¹æ®ç±»å‹æ ‡è¯†ç¬¦æŸ¥æ‰¾å®ä½“ç±»å‹

        Args:
            entity_type: å®ä½“ç±»å‹æ ‡è¯†ç¬¦

        Returns:
            å®ä½“ç±»å‹å¯¹è±¡ï¼Œå¦‚æœæœªæ‰¾åˆ°è¿”å› None
        """
        for et in self.entity_types:
            if et.type == entity_type:
                return et
        return None

    def _get_entity_type_weight(self, entity_type: str) -> float:
        """
        è·å–å®ä½“ç±»å‹æƒé‡

        Args:
            entity_type: å®ä½“ç±»å‹

        Returns:
            æƒé‡å€¼
        """
        # ä»åŠ è½½çš„å®ä½“ç±»å‹ä¸­æŸ¥æ‰¾
        entity_type_obj = self._get_entity_type_by_type(entity_type)
        if entity_type_obj:
            return float(entity_type_obj.weight)

        # é»˜è®¤æƒé‡
        return 1.0
