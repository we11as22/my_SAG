"""
ResearcherAgent - æ™ºèƒ½å¯¹è¯ç ”ç©¶å‘˜

æ ¸å¿ƒèƒ½åŠ›ï¼š
- ğŸ§  è®¤çŸ¥ç†è§£ï¼šæ·±åº¦ç†è§£é—®é¢˜æ„å›¾å’Œä¸Šä¸‹æ–‡
- ğŸ” ä¸»åŠ¨æœç´¢ï¼šåŸºäºçŸ¥è¯†ç¼ºå£ä¸»åŠ¨æœç´¢
- ğŸ’­ æ¨ç†é“¾è·¯ï¼šå®Œæ•´çš„æ€è€ƒé“¾ï¼ˆCoTï¼‰
- ğŸ“Š è‡ªæˆ‘è¯„ä¼°ï¼šæ¯ä¸ªé˜¶æ®µè‡ªæˆ‘è¯„ä¼°è´¨é‡
- ğŸ”„ è¿­ä»£ä¼˜åŒ–ï¼šä¸æ–­æ”¹è¿›ç›´åˆ°æ»¡æ„
- ğŸ“ è®°å¿†ç®¡ç†ï¼šç»“æ„åŒ–å¯¹è¯å’ŒçŸ¥è¯†è®°å¿†
"""

from typing import Any, AsyncIterator, Dict, List, Optional
from sag.core.agent.base import BaseAgent
from sag.modules.search import SAGSearcher, SearchConfig
from sag.core.ai.models import LLMMessage, LLMRole
from sag.core.prompt import get_prompt_manager
from sag.utils import get_logger

logger = get_logger("agent.researcher")


class ResearcherAgent(BaseAgent):
    """
    ç ”ç©¶å‘˜ Agent - å…·æœ‰å®Œæ•´è®¤çŸ¥èƒ½åŠ›çš„å¯¹è¯ Agent

    è®¤çŸ¥æµç¨‹ï¼š
    1. Understanding  - ç†è§£é˜¶æ®µï¼ˆé—®é¢˜åˆ†æï¼‰
    2. Planning      - è§„åˆ’é˜¶æ®µï¼ˆåˆ¶å®šç­–ç•¥ï¼‰
    3. Researching   - ç ”ç©¶é˜¶æ®µï¼ˆä¸»åŠ¨æœç´¢ï¼‰
    4. Evaluating    - è¯„ä¼°é˜¶æ®µï¼ˆçŸ¥è¯†æ£€æŸ¥ï¼‰
    5. Synthesizing  - ç»¼åˆé˜¶æ®µï¼ˆæ•´åˆç­”æ¡ˆï¼‰
    6. Verifying     - éªŒè¯é˜¶æ®µï¼ˆè´¨é‡æŠŠå…³ï¼‰
    """

    # æ¨¡å¼å®šä¹‰
    MODE_QUICK = "quick"  # å¿«é€Ÿï¼šå•è½®æœç´¢
    MODE_DEEP = "deep"    # æ·±åº¦ï¼šå¤šè½®è¿­ä»£

    # è®¤çŸ¥é˜¶æ®µ
    STAGE_UNDERSTANDING = "understanding"
    STAGE_PLANNING = "planning"
    STAGE_RESEARCHING = "researching"
    STAGE_EVALUATING = "evaluating"
    STAGE_SYNTHESIZING = "synthesizing"
    STAGE_VERIFYING = "verifying"

    def __init__(
        self,
        source_config_ids: Optional[List[str]] = None,
        mode: str = MODE_QUICK,
        conversation_history: Optional[List[Dict]] = None,
        **kwargs
    ):
        """
        åˆå§‹åŒ– ResearcherAgent

        Args:
            source_config_ids: ä¿¡æ¯æºIDåˆ—è¡¨
            mode: å¯¹è¯æ¨¡å¼ï¼ˆquick/deepï¼‰
            conversation_history: å¯¹è¯å†å²ï¼ˆæœ€è¿‘10è½®ï¼‰
        """
        # è®¾ç½®è¾“å‡ºé…ç½®
        if "output" not in kwargs:
            kwargs["output"] = {
                "stream": True,   # æµå¼è¾“å‡º
                "think": True,    # æ˜¾ç¤ºæ€è€ƒ
                "format": "text",
                "style": "å‹å¥½ã€ä¸“ä¸šã€å‡†ç¡®ã€‚é€»è¾‘æ¸…æ™°ï¼Œé‡ç‚¹çªå‡ºã€‚å–„ç”¨ç»“æ„åŒ–è¡¨è¾¾ã€‚"
            }

        super().__init__(**kwargs)

        # ğŸ”§ é‡è½½ agent_config ä½¿ç”¨ researcher.json
        try:
            prompt_manager = get_prompt_manager()
            self.agent_config = prompt_manager.load_json_config("researcher")
            # æ›´æ–° builder
            from sag.core.agent.builder import Builder
            self.builder = Builder(self.agent_config)
            logger.info("æˆåŠŸåŠ è½½ researcher.json é…ç½®")
        except Exception as e:
            logger.warning(f"åŠ è½½ researcher.json å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ agent.json: {e}")

        self.source_config_ids = source_config_ids or []
        self.mode = mode

        # åˆå§‹åŒ–æœç´¢å™¨ï¼ˆä¼ é€’ model_configï¼Œç»§æ‰¿è‡ª BaseAgentï¼‰
        self.searcher = SAGSearcher(
            prompt_manager=get_prompt_manager(),
            model_config=self.model_config  # ä½¿ç”¨ BaseAgent çš„ model_config
        )

        # è®¤çŸ¥çŠ¶æ€
        self.current_stage = None
        self.understanding: Optional[Dict] = None  # é—®é¢˜ç†è§£ç»“æœ
        self.search_plan: Optional[Dict] = None    # æœç´¢è®¡åˆ’
        self.knowledge_graph: List[Dict] = []       # çŸ¥è¯†å›¾è°±
        self.confidence_score: float = 0.0          # å›ç­”ç½®ä¿¡åº¦

        # æœç´¢å‚æ•°ï¼ˆé»˜è®¤å€¼ï¼‰
        self.search_params = {
            "top_k": 10,
            "threshold": 0.5,  # ç›¸ä¼¼åº¦é˜ˆå€¼
            "result_style": "concise"
        }

        # åŠ è½½å¯¹è¯å†å²åˆ°è®°å¿†
        if conversation_history:
            self._load_conversation_memory(conversation_history)

        logger.info(
            f"åˆå§‹åŒ– ResearcherAgent",
            extra={
                "mode": mode,
                "sources": len(self.source_config_ids),
                "has_history": bool(conversation_history)
            }
        )

    # ============ ä¸»å…¥å£ ============

    async def chat(
        self,
        query: str,
        source_config_ids: Optional[List[str]] = None,
        **kwargs
    ) -> AsyncIterator[Dict[str, Any]]:
        """
        å¯¹è¯å…¥å£ï¼ˆæµå¼è¾“å‡ºï¼‰

        Args:
            query: ç”¨æˆ·é—®é¢˜
            source_config_ids: ä¿¡æ¯æºåˆ—è¡¨ï¼ˆå¯è¦†ç›–ï¼‰
            **kwargs: å‚æ•°ï¼ˆä¼šè‡ªåŠ¨åˆ†ç¦»æœç´¢å‚æ•°å’ŒLLMå‚æ•°ï¼‰

        Yields:
            {
                "type": "stage|thinking|content|done|error",
                "stage": "understanding|planning|...",  # å½“å‰é˜¶æ®µ
                "content": "...",                       # å†…å®¹
                "data": {...}                           # é˜¶æ®µæ•°æ®
            }
        """
        # æ›´æ–°ä¿¡æ¯æº
        if source_config_ids:
            self.source_config_ids = source_config_ids

        # éªŒè¯
        if not self.source_config_ids:
            yield {
                "type": "error",
                "content": "è¯·å…ˆé€‰æ‹©ä¿¡æ¯æº"
            }
            return

        # ğŸ”§ åˆ†ç¦»æœç´¢å‚æ•°å’Œ LLM å‚æ•°
        # æœç´¢å‚æ•°ï¼štop_k, threshold, result_style ç­‰
        if "top_k" in kwargs:
            self.search_params["top_k"] = kwargs.pop("top_k")
            logger.info(f"âœ… æ¥æ”¶åˆ°å‰ç«¯ top_k å‚æ•°: {self.search_params['top_k']}")
        if "threshold" in kwargs:
            self.search_params["threshold"] = kwargs.pop("threshold")
            logger.info(
                f"âœ… æ¥æ”¶åˆ°å‰ç«¯ threshold å‚æ•°: {self.search_params['threshold']}")
        if "result_style" in kwargs:
            self.search_params["result_style"] = kwargs.pop("result_style")

        logger.info(f"ğŸ” å½“å‰æœç´¢å‚æ•°: {self.search_params}")

        # kwargs å‰©ä½™çš„æ‰æ˜¯ LLM å‚æ•°ï¼ˆå¦‚ temperature, max_tokens ç­‰ï¼‰

        # è®°å½•ç”¨æˆ·é—®é¢˜åˆ°è®°å¿†
        self._record_user_query(query)

        # æ ¹æ®æ¨¡å¼æ‰§è¡Œï¼ˆä¼ é€’è¿‡æ»¤åçš„ kwargsï¼‰
        try:
            if self.mode == self.MODE_QUICK:
                async for chunk in self._execute_quick_mode(query, **kwargs):
                    yield chunk
            else:
                async for chunk in self._execute_deep_mode(query, **kwargs):
                    yield chunk
        except Exception as e:
            logger.error(f"å¯¹è¯æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            yield {
                "type": "error",
                "content": f"æ‰§è¡Œå¤±è´¥ï¼š{str(e)}"
            }

    # ============ å¿«é€Ÿæ¨¡å¼ ============

    async def _execute_quick_mode(
        self, query: str, **kwargs
    ) -> AsyncIterator[Dict]:
        """
        å¿«é€Ÿæ¨¡å¼ - ç®€æ´é«˜æ•ˆçš„æœç´¢é—®ç­”

        æµç¨‹ï¼š
        1. æœç´¢é˜¶æ®µ - æœç´¢ç›¸å…³äº‹é¡¹
        2. åˆ†æé˜¶æ®µ - å¯é€‰å±•ç¤ºæ¨ç†è¿‡ç¨‹
        3. å›ç­”é˜¶æ®µ - ç”Ÿæˆç­”æ¡ˆ
        """
        import time
        start_time = time.time()

        logger.info(f"ğŸš€ å¿«é€Ÿæ¨¡å¼å¯åŠ¨: query='{query}'")

        # === æ­¥éª¤1ï¼šå¿«é€Ÿåˆ†æ ===
        # ğŸŸ¢ æ‰§è¡Œå‰ç«‹å³è¾“å‡º
        yield {
            "type": "thinking_step",
            "stage": "understanding",
            "label": "å¿«é€Ÿåˆ†æ",
            "content": "åˆ†æé—®é¢˜ç±»å‹å’Œæ ¸å¿ƒæ¦‚å¿µ",
            "status": "processing"
        }

        understanding = await self._understand_question_quick(query)
        self.understanding = understanding
        self._record_understanding(understanding)
        keywords = understanding.get("keywords", [query])

        # ğŸŸ¢ æ‰§è¡Œåç«‹å³æ›´æ–°
        yield {
            "type": "update_step",
            "stage": "understanding",
            "content": f"æå–å…³é”®è¯ï¼š{', '.join(keywords[:5])}",
            "status": "done"
        }

        # === æ­¥éª¤2ï¼šæœç´¢ç ”ç©¶ ===
        yield {
            "type": "thinking_step",
            "stage": "researching",
            "label": "æœç´¢ç ”ç©¶",
            "content": f"æœç´¢ã€Œ{keywords[0] if keywords else query}ã€ç›¸å…³äº‹é¡¹",
            "status": "processing"
        }

        search_result = await self._execute_search(query=query, keywords=keywords)
        events = search_result.get("events", [])

        yield {
            "type": "update_step",
            "stage": "researching",
            "content": f"æ‰¾åˆ° {len(events)} ä¸ªç›¸å…³äº‹é¡¹",
            "status": "done"
        }

        # === æ­¥éª¤3ï¼šè¯„ä¼°çŸ¥è¯† ===
        yield {
            "type": "thinking_step",
            "stage": "evaluating",
            "label": "è¯„ä¼°çŸ¥è¯†",
            "content": "è¯„ä¼°æœç´¢ç»“æœå……åˆ†æ€§",
            "status": "processing"
        }

        evaluation = self._evaluate_knowledge(query, events)
        self.confidence_score = evaluation.get("confidence", 0.0)
        self._record_evaluation(evaluation)

        yield {
            "type": "update_step",
            "stage": "evaluating",
            "content": f"{evaluation['assessment']}ï¼ˆç½®ä¿¡åº¦ {evaluation['confidence']:.0%}ï¼‰",
            "status": "done"
        }

        # === 2. å‡†å¤‡æ•°æ® ===
        if events:
            self._load_events_to_database(events, "æœç´¢ç»“æœ")
            
            # å‘é€å¼•ç”¨äº‹é¡¹ï¼ˆå‰20ä¸ªï¼Œä¸æ•°æ®åº“ä¸€è‡´ï¼‰
            references = []
            for idx, event in enumerate(events[:20], 1):
                references.append({
                    "order": idx,
                    "id": event.id if hasattr(event, 'id') else str(idx),
                    "title": event.title if hasattr(event, 'title') else '',
                    "summary": (event.summary if hasattr(event, 'summary') else '')[:150],
                    "article_id": event.article_id if hasattr(event, 'article_id') else None
                })

            yield {
                "type": "references",
                "data": references
            }

        self._setup_quick_todo(len(events), evaluation)

        # === æ­¥éª¤4ï¼šç”Ÿæˆç­”æ¡ˆ ===
        yield {
            "type": "thinking_step",
            "stage": "synthesizing",
            "label": "ç”Ÿæˆç­”æ¡ˆ",
            "content": "æ•´åˆæ‰€æœ‰ä¿¡æ¯å¹¶æ·±åº¦åˆ†æ",
            "status": "processing"
        }

        show_reasoning = kwargs.get("show_reasoning", True)

        async for chunk in super().run_stream(query=query, **kwargs):
            if chunk.get("reasoning") and show_reasoning:
                yield {
                    "type": "reasoning",
                    "content": chunk["reasoning"]
                }
            if chunk.get("content"):
                yield {
                    "type": "content",
                    "content": chunk["content"]
                }

        # ç”Ÿæˆå®Œæ¯•
        yield {
            "type": "update_step",
            "stage": "synthesizing",
            "content": "å®Œæˆ",
            "status": "done"
        }

        # === å®Œæˆ ===
        thinking_time = time.time() - start_time

        yield {
            "type": "done",
            "stats": {
                "mode": "quick",
                "events_found": len(events),
                "confidence": evaluation.get("confidence", 0.0),
                "sources": len(self.source_config_ids),
                "thinking_time": round(thinking_time, 2)  # æ€è€ƒè€—æ—¶ï¼ˆç§’ï¼‰
            }
        }

    # ============ æ·±åº¦æ¨¡å¼ ============

    async def _execute_deep_mode(
        self, query: str, **kwargs
    ) -> AsyncIterator[Dict]:
        """
        æ·±åº¦æ¨¡å¼ - å¤šè½®è¿­ä»£æ·±å…¥ç ”ç©¶

        æµç¨‹ï¼š
        1. æ·±åº¦ç†è§£å’Œè§„åˆ’
        2. å¤šè½®æœç´¢è¿­ä»£
        3. æ·±åº¦åˆ†æå’Œç»¼åˆ
        """
        import time
        start_time = time.time()

        logger.info(f"ğŸ§  æ·±åº¦æ¨¡å¼å¯åŠ¨: query='{query}'")

        # === æ­¥éª¤1ï¼šæ·±åº¦ç†è§£ ===
        yield {
            "type": "thinking_step",
            "stage": "understanding",
            "label": "æ·±åº¦ç†è§£",
            "content": "åˆ†æé—®é¢˜ç±»å‹å’Œæ ¸å¿ƒæ¦‚å¿µ",
            "status": "processing"
        }

        understanding = await self._understand_question_deep(query)
        self.understanding = understanding
        self._record_understanding(understanding)

        yield {
            "type": "update_step",
            "stage": "understanding",
            "content": f"é—®é¢˜ç±»å‹ï¼š{understanding.get('question_type')}ï¼Œæ ¸å¿ƒæ¦‚å¿µï¼š{', '.join(understanding.get('concepts', [])[:3])}",
            "status": "done"
        }

        # === æ­¥éª¤2ï¼šåˆ¶å®šè®¡åˆ’ ===
        yield {
            "type": "thinking_step",
            "stage": "planning",
            "label": "åˆ¶å®šè®¡åˆ’",
            "content": "è§„åˆ’å¤šè½®æœç´¢ç­–ç•¥",
            "status": "processing"
        }

        search_plan = await self._create_search_plan(query, understanding)
        self.search_plan = search_plan
        self._record_search_plan(search_plan)

        yield {
            "type": "update_step",
            "stage": "planning",
            "content": f"è®¡åˆ’ {search_plan.get('rounds', 1)} è½®æœç´¢",
            "status": "done"
        }

        # === æ­¥éª¤3ï¼šå¤šè½®æœç´¢ï¼ˆåŠ¨æ€ï¼‰ ===
        all_events = []
        max_rounds = min(search_plan.get("rounds", 3), 5)

        for round_idx in range(max_rounds):
            queries = search_plan.get("queries", [[query]])[round_idx] if round_idx < len(
                search_plan.get("queries", [])) else [query]

            # ğŸŸ¢ æœ¬è½®æœç´¢å¼€å§‹
            yield {
                "type": "thinking_step",
                "stage": f"round_{round_idx + 1}",
                "label": f"ç¬¬ {round_idx + 1} è½®æœç´¢",
                "content": f"æŸ¥è¯¢ï¼š{queries if isinstance(queries, list) else [queries]}",
                "status": "processing"
            }

            round_events = await self._execute_multi_query_search(
                queries if isinstance(queries, list) else [queries]
            )

            all_events.extend(round_events)
            all_events = self._deduplicate_events(all_events)

            # ğŸŸ¢ æœ¬è½®ç»“æœ
            yield {
                "type": "update_step",
                "stage": f"round_{round_idx + 1}",
                "content": f"æ‰¾åˆ° {len(round_events)} ä¸ªäº‹é¡¹ï¼Œç´¯è®¡ {len(all_events)} ä¸ª",
                "status": "done"
            }

            # è¯„ä¼°
            evaluation = await self._evaluate_knowledge_deep(query, all_events, round_idx + 1)
            self._record_evaluation(evaluation)

            if evaluation["is_sufficient"]:
                # ğŸŸ¢ çŸ¥è¯†å……åˆ†
                yield {
                    "type": "thinking_step",
                    "stage": "decision",
                    "label": "è¯„ä¼°å†³ç­–",
                    "content": f"{evaluation['assessment']}ï¼Œç»“æŸæœç´¢",
                    "status": "done"
                }
                logger.info(f"âœ… çŸ¥è¯†å……åˆ†ï¼Œç»“æŸæœç´¢ï¼ˆ{round_idx + 1} è½®ï¼‰")
                break
            else:
                # ğŸŸ¢ ç»§ç»­æœç´¢
                yield {
                    "type": "thinking_step",
                    "stage": f"decision_{round_idx}",
                    "label": "è¯„ä¼°å†³ç­–",
                    "content": f"çŸ¥è¯†ä¸è¶³ï¼Œç»§ç»­ç¬¬ {round_idx + 2} è½®æœç´¢",
                    "status": "done"
                }

        # æœç´¢å®Œæˆé€šçŸ¥
        yield {
            "type": "search_status",
            "status": "done",
            "sources_count": len(self.source_config_ids),
            "events_count": len(all_events),
            "confidence": evaluation.get("confidence", 0.0)
        }

        # === 2. å‡†å¤‡æ•°æ® ===
        if all_events:
            self._load_events_to_database(all_events, f"æ·±åº¦ç ”ç©¶ç»“æœï¼ˆ{round_idx + 1} è½®ï¼‰")
            
            # å‘é€å¼•ç”¨äº‹é¡¹ï¼ˆå‰20ä¸ªï¼Œä¸æ•°æ®åº“ä¸€è‡´ï¼‰
            references = []
            for idx, event in enumerate(all_events[:20], 1):
                references.append({
                    "order": idx,
                    "id": event.id if hasattr(event, 'id') else str(idx),
                    "title": event.title if hasattr(event, 'title') else '',
                    "summary": (event.summary if hasattr(event, 'summary') else '')[:150],
                    "article_id": event.article_id if hasattr(event, 'article_id') else None
                })

            yield {
                "type": "references",
                "data": references
            }

        self._setup_deep_todo(len(all_events), evaluation)

        # === æ­¥éª¤Nï¼šç”Ÿæˆæ·±åº¦ç­”æ¡ˆ ===
        yield {
            "type": "thinking_step",
            "stage": "synthesizing",
            "label": "æ·±åº¦ç»¼åˆ",
            "content": "æ•´åˆæ‰€æœ‰ä¿¡æ¯å¹¶æ·±åº¦åˆ†æ",
            "status": "processing"
        }

        show_reasoning = kwargs.get("show_reasoning", True)

        async for chunk in super().run_stream(query=query, **kwargs):
            if chunk.get("reasoning") and show_reasoning:
                yield {
                    "type": "reasoning",
                    "content": chunk["reasoning"]
                }
            if chunk.get("content"):
                yield {
                    "type": "content",
                    "content": chunk["content"]
                }

        # ğŸŸ¢ æ·±åº¦åˆ†æå®Œæˆ
        yield {
            "type": "update_step",
            "stage": "synthesizing",
            "content": "å®Œæˆ",
            "status": "done"
        }

        # === å®Œæˆ ===
        thinking_time = time.time() - start_time

        yield {
            "type": "done",
            "stats": {
                "mode": "deep",
                "search_rounds": round_idx + 1,
                "events_found": len(all_events),
                "confidence": evaluation.get("confidence", 0.0),
                "sources": len(self.source_config_ids),
                "thinking_time": round(thinking_time, 2)
            }
        }

    # ============ è®¤çŸ¥èƒ½åŠ›æ–¹æ³• ============

    async def _understand_question_quick(self, query: str) -> Dict:
        """
        å¿«é€Ÿç†è§£é—®é¢˜

        æå–ï¼š
        - intent: ç”¨æˆ·æ„å›¾
        - keywords: å…³é”®è¯åˆ—è¡¨
        - entity_types: å…³é”®å®ä½“ç±»å‹
        """
        schema = {
            "type": "object",
            "properties": {
                "intent": {"type": "string", "description": "ç”¨æˆ·æ„å›¾ï¼Œä¸€å¥è¯æ¦‚æ‹¬"},
                "keywords": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "å…³é”®è¯åˆ—è¡¨ï¼ˆ2-5ä¸ªï¼‰"
                },
                "entity_types": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "å…³é”®å®ä½“ç±»å‹"
                },
            },
            "required": ["intent", "keywords"]
        }

        messages = [
            LLMMessage(
                role=LLMRole.SYSTEM,
                content="ä½ æ˜¯é—®é¢˜åˆ†æä¸“å®¶ï¼Œå¿«é€Ÿæå–é—®é¢˜ä¸­çš„å…³é”®ä¿¡æ¯ã€‚"
            ),
            LLMMessage(
                role=LLMRole.USER,
                content=f"åˆ†æé—®é¢˜ï¼Œæå–å…³é”®è¯ï¼š{query}"
            )
        ]

        llm_client = await self._get_llm_client()
        result = await llm_client.chat_with_schema(
            messages=messages,
            response_schema=schema
        )

        logger.info(
            f"å¿«é€Ÿç†è§£: intent={result.get('intent')}, keywords={result.get('keywords')}")
        return result

    async def _understand_question_deep(self, query: str) -> Dict:
        """
        æ·±åº¦ç†è§£é—®é¢˜

        åˆ†æï¼š
        - question_type: é—®é¢˜ç±»å‹
        - concepts: æ ¸å¿ƒæ¦‚å¿µåˆ—è¡¨
        - sub_questions: å­é—®é¢˜åˆ†è§£
        - time_range: æ—¶é—´èŒƒå›´
        - focus_entities: å…³æ³¨çš„å®ä½“ç±»å‹
        """
        schema = {
            "type": "object",
            "properties": {
                "question_type": {
                    "type": "string",
                    "enum": ["äº‹å®æŸ¥è¯¢", "å¯¹æ¯”åˆ†æ", "è¶‹åŠ¿åˆ†æ", "åŸå› æ¢ç©¶", "æ–¹æ¡ˆå»ºè®®"],
                    "description": "é—®é¢˜ç±»å‹"
                },
                "concepts": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "æ ¸å¿ƒæ¦‚å¿µï¼ˆ2-5ä¸ªï¼‰"
                },
                "sub_questions": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "åˆ†è§£çš„å­é—®é¢˜ï¼ˆ2-4ä¸ªï¼‰"
                },
                "time_range": {
                    "type": "string",
                    "description": "æ—¶é—´èŒƒå›´ï¼ˆå¦‚ï¼š2024å¹´ã€è¿‘æœŸã€å†å²ï¼‰"
                },
                "focus_entities": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "å…³æ³¨çš„å®ä½“ç±»å‹"
                }
            },
            "required": ["question_type", "concepts"]
        }

        messages = [
            LLMMessage(
                role=LLMRole.SYSTEM,
                content="""ä½ æ˜¯é—®é¢˜åˆ†æä¸“å®¶ï¼Œè¿›è¡Œæ·±åº¦é—®é¢˜ç†è§£ã€‚

åˆ†æç»´åº¦ï¼š
1. é—®é¢˜ç±»å‹ï¼šåˆ¤æ–­é—®é¢˜å±äºå“ªç§ç±»å‹
2. æ ¸å¿ƒæ¦‚å¿µï¼šæå–2-5ä¸ªæœ€æ ¸å¿ƒçš„æ¦‚å¿µ
3. å­é—®é¢˜ï¼šå°†å¤æ‚é—®é¢˜åˆ†è§£ä¸º2-4ä¸ªå…·ä½“çš„å­é—®é¢˜
4. æ—¶é—´èŒƒå›´ï¼šè¯†åˆ«æ—¶é—´é™å®šï¼ˆå¦‚æœæœ‰ï¼‰
5. å…³æ³¨å®ä½“ï¼šéœ€è¦é‡ç‚¹å…³æ³¨å“ªäº›å®ä½“ç±»å‹ï¼ˆäººç‰©ã€åœ°ç‚¹ã€æ—¶é—´ç­‰ï¼‰"""
            ),
            LLMMessage(
                role=LLMRole.USER,
                content=f"æ·±åº¦åˆ†æä»¥ä¸‹é—®é¢˜ï¼š\n\n{query}"
            )
        ]

        llm_client = await self._get_llm_client()
        result = await llm_client.chat_with_schema(
            messages=messages,
            response_schema=schema
        )

        logger.info(
            f"æ·±åº¦ç†è§£: type={result.get('question_type')}, concepts={result.get('concepts')}")
        return result

    async def _create_search_plan(
        self, query: str, understanding: Dict
    ) -> Dict:
        """
        åˆ¶å®šæœç´¢è®¡åˆ’

        è¿”å›ï¼š
        {
            "rounds": 3,
            "queries": [
                ["ä¸»å…³é”®è¯1", "ä¸»å…³é”®è¯2"],  # ç¬¬1è½®
                ["è¡¥å……æ¦‚å¿µ1"],               # ç¬¬2è½®  
                ["å…³è”ä¿¡æ¯1"]                # ç¬¬3è½®
            ],
            "strategy": "æœç´¢ç­–ç•¥è¯´æ˜"
        }
        """
        schema = {
            "type": "object",
            "properties": {
                "rounds": {
                    "type": "integer",
                    "minimum": 1,
                    "maximum": 5,
                    "description": "è®¡åˆ’çš„æœç´¢è½®æ•°"
                },
                "queries": {
                    "type": "array",
                    "items": {
                        "type": "array",
                        "items": {"type": "string"}
                    },
                    "description": "æ¯è½®çš„æŸ¥è¯¢åˆ—è¡¨"
                },
                "strategy": {
                    "type": "string",
                    "description": "æœç´¢ç­–ç•¥è¯´æ˜"
                }
            },
            "required": ["rounds", "queries"]
        }

        messages = [
            LLMMessage(
                role=LLMRole.SYSTEM,
                content="""ä½ æ˜¯æœç´¢ç­–ç•¥ä¸“å®¶ï¼Œåˆ¶å®šå¤šè½®æœç´¢è®¡åˆ’ã€‚

åŸåˆ™ï¼š
1. ç¬¬1è½®ï¼šæœ€æ ¸å¿ƒã€æœ€ç›´æ¥çš„å…³é”®è¯
2. ç¬¬2è½®ï¼šè¡¥å……æ¦‚å¿µã€åŒä¹‰è¯ã€ç›¸å…³æœ¯è¯­
3. ç¬¬3è½®ï¼šå…³è”ä¿¡æ¯ã€èƒŒæ™¯çŸ¥è¯†
4. æ¯è½®1-2ä¸ªæŸ¥è¯¢ï¼Œé¿å…è¿‡å¤š
5. ä»ä¸»åˆ°æ¬¡ï¼Œä»ç›´æ¥åˆ°å…³è”"""
            ),
            LLMMessage(
                role=LLMRole.USER,
                content=f"""é—®é¢˜ï¼š{query}

ç†è§£ç»“æœï¼š
- é—®é¢˜ç±»å‹ï¼š{understanding.get('question_type')}
- æ ¸å¿ƒæ¦‚å¿µï¼š{understanding.get('concepts')}
- å­é—®é¢˜ï¼š{understanding.get('sub_questions')}

è¯·åˆ¶å®šè¯¦ç»†çš„æœç´¢è®¡åˆ’ã€‚"""
            )
        ]

        llm_client = await self._get_llm_client()
        plan = await llm_client.chat_with_schema(
            messages=messages,
            response_schema=schema
        )

        logger.info(
            f"æœç´¢è®¡åˆ’: rounds={plan.get('rounds')}, queries={plan.get('queries')}")
        return plan

    async def _execute_search(
        self, query: str, keywords: List[str]
    ) -> Dict:
        """
        æ‰§è¡Œå•æ¬¡æœç´¢ï¼ˆæ”¯æŒå¤šæºï¼‰

        Args:
            query: åŸå§‹æŸ¥è¯¢
            keywords: å…³é”®è¯åˆ—è¡¨
        """
        from sag.modules.search.config import RerankConfig

        search_query = keywords[0] if keywords else query

        logger.info(
            f"ğŸ” æ‰§è¡Œæœç´¢: query='{search_query}', sources={self.source_config_ids}")

        # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šç¡®è®¤å‚æ•°ä¼ é€’
        top_k_value = self.search_params.get("top_k", 10)
        threshold_value = self.search_params.get("threshold", 0.5)
        logger.info(
            f"ğŸ“Š æœç´¢å‚æ•°: top_k={top_k_value}, threshold={threshold_value}")

        # âœ… æ­£ç¡®æ„å»º SearchConfigï¼Œä¼ å…¥ rerank é…ç½®
        result = await self.searcher.search(
            SearchConfig(
                query=search_query,
                source_config_ids=self.source_config_ids,  # âœ… å¤šæºä¸€æ¬¡è°ƒç”¨
                rerank=RerankConfig(
                    max_results=top_k_value,      # ç»“æœæ•°é‡
                    score_threshold=threshold_value  # ç›¸ä¼¼åº¦é˜ˆå€¼
                )
            )
        )

        # è®°å½•æœç´¢åˆ°è®°å¿†
        self._record_search(search_query, result)

        return result

    async def _execute_multi_query_search(
        self, queries: List[str]
    ) -> List:
        """
        æ‰§è¡Œå¤šæŸ¥è¯¢æœç´¢å¹¶åˆå¹¶ç»“æœ

        Args:
            queries: æŸ¥è¯¢åˆ—è¡¨

        Returns:
            åˆå¹¶åçš„äº‹é¡¹åˆ—è¡¨
        """
        all_events = []

        for q in queries:
            result = await self._execute_search(q, [q])
            events = result.get("events", [])
            all_events.extend(events)

            logger.info(f"æŸ¥è¯¢ '{q}' æ‰¾åˆ° {len(events)} ä¸ªäº‹é¡¹")

        return all_events

    def _evaluate_knowledge(
        self, query: str, events: List
    ) -> Dict:
        """
        è¯„ä¼°çŸ¥è¯†å……åˆ†æ€§ï¼ˆåŸºç¡€è¯„ä¼°ï¼‰

        è¿”å›ï¼š
        {
            "is_sufficient": bool,
            "confidence": float,
            "assessment": str,
            "gaps": List[str]
        }
        """
        event_count = len(events)

        if event_count == 0:
            return {
                "is_sufficient": False,
                "confidence": 0.0,
                "assessment": "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯",
                "gaps": ["å®Œå…¨ç¼ºå°‘ç›¸å…³æ•°æ®"]
            }

        if event_count >= 5:
            return {
                "is_sufficient": True,
                "confidence": 0.85,
                "assessment": "ä¿¡æ¯å……åˆ†ï¼Œå¯ä»¥ç»™å‡ºå®Œæ•´å›ç­”",
                "gaps": []
            }

        if event_count >= 2:
            return {
                "is_sufficient": True,
                "confidence": 0.65,
                "assessment": "ä¿¡æ¯åŸºæœ¬å……åˆ†ï¼Œå¯ä»¥ç»™å‡ºåˆæ­¥å›ç­”",
                "gaps": ["éƒ¨åˆ†ç»†èŠ‚å¯èƒ½ä¸å®Œæ•´"]
            }

        return {
            "is_sufficient": True,
            "confidence": 0.4,
            "assessment": "ä¿¡æ¯æœ‰é™ï¼Œä»…èƒ½ç»™å‡ºéƒ¨åˆ†å›ç­”",
            "gaps": ["ç›¸å…³ä¿¡æ¯è¾ƒå°‘ï¼Œç­”æ¡ˆå¯èƒ½ä¸å…¨é¢"]
        }

    async def _evaluate_knowledge_deep(
        self, query: str, events: List, round_idx: int
    ) -> Dict:
        """
        æ·±åº¦è¯„ä¼°çŸ¥è¯†ï¼ˆè€ƒè™‘è¿­ä»£è½®æ¬¡ï¼‰

        ç­–ç•¥ï¼š
        - æ—©æœŸè½®æ¬¡ï¼šè¦æ±‚è¾ƒé«˜ï¼ˆè‡³å°‘5ä¸ªäº‹é¡¹ï¼‰
        - åæœŸè½®æ¬¡ï¼šé™ä½æ ‡å‡†ï¼ˆè‡³å°‘3ä¸ªäº‹é¡¹ï¼‰
        """
        basic_eval = self._evaluate_knowledge(query, events)

        # æ·±åº¦æ¨¡å¼ï¼šæ ¹æ®è½®æ¬¡è°ƒæ•´åˆ¤æ–­
        if round_idx >= 2:
            # å·²ç»æœç´¢2è½®ä»¥ä¸Šï¼Œé™ä½æ ‡å‡†
            if len(events) >= 3:
                basic_eval["is_sufficient"] = True
                basic_eval["assessment"] = f"ç»è¿‡ {round_idx} è½®æœç´¢ï¼Œå·²æ”¶é›†è¶³å¤Ÿä¿¡æ¯"
                basic_eval["confidence"] = max(basic_eval["confidence"], 0.7)

        return basic_eval

    # ============ è®°å¿†ç®¡ç† ============

    def _load_conversation_memory(self, history: List[Dict]):
        """åŠ è½½å¯¹è¯å†å²åˆ°è®°å¿†ï¼ˆå®‰å…¨åºåˆ—åŒ–ï¼‰"""
        # åªä¿ç•™æœ€è¿‘10æ¡
        recent_history = history[-10:]

        # è¿‡æ»¤å’Œè½¬æ¢æ‰€æœ‰å­—æ®µ
        safe_history = []
        for msg in recent_history:
            safe_msg = {
                "role": msg.get("role", ""),
                "content": msg.get("content", ""),
            }

            # å¯é€‰å­—æ®µï¼ˆåªä¿ç•™åŸºæœ¬ç±»å‹ï¼‰
            if "sources" in msg and isinstance(msg["sources"], list):
                safe_msg["sources"] = msg["sources"]

            # âœ… timestamp è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            if "timestamp" in msg:
                ts = msg["timestamp"]
                if hasattr(ts, 'isoformat'):
                    safe_msg["timestamp"] = ts.isoformat()
                elif isinstance(ts, str):
                    safe_msg["timestamp"] = ts
                else:
                    safe_msg["timestamp"] = str(ts)

            safe_history.append(safe_msg)

        self.add_memory(
            data_type="å¯¹è¯å†å²",
            items=safe_history,
            description=f"æœ€è¿‘ {len(safe_history)} æ¡å¯¹è¯è®°å½•"
        )

    def _record_user_query(self, query: str):
        """è®°å½•ç”¨æˆ·é—®é¢˜"""
        self.add_memory(
            data_type="å½“å‰é—®é¢˜",
            items=[{
                "query": query,
                "timestamp": self._get_current_time(),  # è¿”å› ISO å­—ç¬¦ä¸²ï¼Œå¯åºåˆ—åŒ–
                "mode": self.mode,
                "sources": self.source_config_ids
            }],
            description="æœ¬æ¬¡å¯¹è¯çš„ç”¨æˆ·é—®é¢˜"
        )

    def _record_understanding(self, understanding: Dict):
        """è®°å½•é—®é¢˜ç†è§£ï¼ˆåªä¿ç•™åŸºæœ¬ä¿¡æ¯ï¼‰"""
        # åªä¿ç•™å¯åºåˆ—åŒ–çš„åŸºæœ¬ä¿¡æ¯
        safe_understanding = {
            "intent": understanding.get("intent", ""),
            "keywords": understanding.get("keywords", [])[:5],
            "question_type": understanding.get("question_type", ""),
            "concepts": understanding.get("concepts", [])[:5],
        }

        self.add_memory(
            data_type="é—®é¢˜ç†è§£",
            items=[safe_understanding],
            description="å¯¹ç”¨æˆ·é—®é¢˜çš„è®¤çŸ¥åˆ†æ"
        )

    def _record_search_plan(self, plan: Dict):
        """è®°å½•æœç´¢è®¡åˆ’ï¼ˆåªä¿ç•™åŸºæœ¬ä¿¡æ¯ï¼‰"""
        # åªä¿ç•™å¯åºåˆ—åŒ–çš„åŸºæœ¬ä¿¡æ¯
        safe_plan = {
            "rounds": plan.get("rounds", 1),
            "queries": plan.get("queries", [])[:5],  # æœ€å¤šä¿ç•™5è½®
            "strategy": plan.get("strategy", "")
        }

        self.add_memory(
            data_type="æœç´¢è®¡åˆ’",
            items=[safe_plan],
            description="åˆ¶å®šçš„å¤šè½®æœç´¢ç­–ç•¥"
        )

    def _record_search(self, query: str, result: Dict):
        """è®°å½•æœç´¢ç»“æœï¼ˆåªä¿ç•™åŸºæœ¬ä¿¡æ¯ï¼Œé¿å…åºåˆ—åŒ–é—®é¢˜ï¼‰"""
        self.add_memory(
            data_type="æœç´¢å†å²",
            items=[{
                "query": query,
                "event_count": len(result.get("events", [])),
                # ä¸ä¿å­˜å¤æ‚çš„ stats å¯¹è±¡ï¼Œé¿å…åºåˆ—åŒ–é—®é¢˜
                "timestamp": self._get_current_time()  # ISO å­—ç¬¦ä¸²
            }],
            description="æœç´¢æ‰§è¡Œè®°å½•"
        )

    def _record_evaluation(self, evaluation: Dict):
        """è®°å½•çŸ¥è¯†è¯„ä¼°"""
        self.add_memory(
            data_type="çŸ¥è¯†è¯„ä¼°",
            items=[evaluation],
            description="å¯¹å½“å‰çŸ¥è¯†åº“çš„è¯„ä¼°ç»“æœ"
        )

    def _load_events_to_database(self, events: List, description: str):
        """åŠ è½½äº‹é¡¹åˆ°æ•°æ®åº“ï¼ˆå¸¦åºå·ï¼Œå®Œå…¨åºåˆ—åŒ–æ‰€æœ‰å­—æ®µï¼‰"""
        self.clear_database(data_type="æœç´¢äº‹é¡¹")

        items = []
        for idx, event in enumerate(events[:20], 1):
            # åŸºæœ¬å­—æ®µ
            item = {
                "order": idx,
                "id": str(event.id) if hasattr(event, 'id') else str(idx),
                "title": str(event.title) if hasattr(event, 'title') else '',
                "summary": str(event.summary) if hasattr(event, 'summary') else '',
                "content": str(event.content) if hasattr(event, 'content') else '',
                "source_id": str(event.source_id) if hasattr(event, 'source_id') else 'unknown',
            }

            # å¯é€‰å­—æ®µ
            if hasattr(event, 'category') and event.category:
                item["category"] = str(event.category)

            if hasattr(event, 'rank'):
                item["rank"] = int(event.rank) if isinstance(
                    event.rank, int) else 0

            # âœ… datetime å­—æ®µï¼šè½¬æ¢ä¸º ISO å­—ç¬¦ä¸²ï¼ˆä¿ç•™æ—¶é—´ä¿¡æ¯ï¼‰
            if hasattr(event, 'start_time') and event.start_time:
                try:
                    item["start_time"] = event.start_time.isoformat()
                except:
                    item["start_time"] = str(event.start_time)

            if hasattr(event, 'end_time') and event.end_time:
                try:
                    item["end_time"] = event.end_time.isoformat()
                except:
                    item["end_time"] = str(event.end_time)

            # created_time å’Œ updated_time ä¹Ÿè½¬æ¢
            if hasattr(event, 'created_time') and event.created_time:
                try:
                    item["created_time"] = event.created_time.isoformat()
                except:
                    item["created_time"] = str(event.created_time)

            if hasattr(event, 'updated_time') and event.updated_time:
                try:
                    item["updated_time"] = event.updated_time.isoformat()
                except:
                    item["updated_time"] = str(event.updated_time)

            items.append(item)

        self.add_database(
            data_type="æœç´¢äº‹é¡¹",
            items=items,
            description=description
        )

    # ============ TODO ä»»åŠ¡è®¾ç½® ============

    def _setup_quick_todo(self, event_count: int, evaluation: Dict):
        """å¿«é€Ÿæ¨¡å¼ TODO"""
        self.clear_todo()

        if event_count == 0:
            self.add_todo(
                task_id="no-data-response",
                description="æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚ç¤¼è²Œå‘ŠçŸ¥ç”¨æˆ·ï¼Œå»ºè®®ï¼š1) æ¢ä¸ªè¡¨è¿°æ–¹å¼ 2) é€‰æ‹©å…¶ä»–ä¿¡æ¯æº 3) æä¾›æ›´å¤šä¸Šä¸‹æ–‡",
                status="pending",
                priority=10
            )
        else:
            self.add_todo(
                task_id="analyze-relevance",
                description=f"åˆ†æ {event_count} ä¸ªäº‹é¡¹ä¸é—®é¢˜çš„ç›¸å…³æ€§ï¼Œç­›é€‰æœ€ç›¸å…³çš„å†…å®¹",
                status="pending",
                priority=10
            )

            self.add_todo(
                task_id="extract-key-info",
                description="ä»ç›¸å…³äº‹é¡¹ä¸­æå–å…³é”®ä¿¡æ¯ï¼šæ ¸å¿ƒè§‚ç‚¹ã€æ•°æ®ã€æ—¶é—´ã€äººç‰©ç­‰",
                status="pending",
                priority=9
            )

            self.add_todo(
                task_id="synthesize-answer",
                description="åŸºäºæå–çš„ä¿¡æ¯ç”Ÿæˆç®€æ´å›ç­”ï¼Œé€»è¾‘æ¸…æ™°ã€é‡ç‚¹çªå‡ºã€‚å¼•ç”¨äº‹é¡¹åºå· [#1][#2]",
                status="pending",
                priority=8
            )

            # å¦‚æœç½®ä¿¡åº¦ä¸é«˜ï¼Œæ·»åŠ è¯´æ˜ä»»åŠ¡
            if evaluation.get("confidence", 0) < 0.7:
                self.add_todo(
                    task_id="add-disclaimer",
                    description=f"åœ¨å›ç­”æœ«å°¾è¯´æ˜ï¼š{evaluation.get('assessment')}ï¼Œç­”æ¡ˆå¯èƒ½ä¸å®Œæ•´",
                    status="pending",
                    priority=7
                )

    def _setup_deep_todo(self, event_count: int, evaluation: Dict):
        """æ·±åº¦æ¨¡å¼ TODO"""
        self.clear_todo()

        if event_count == 0:
            self.add_todo(
                task_id="no-data-analysis",
                description="æ·±åº¦åˆ†æä¸ºä½•æ²¡æœ‰æ‰¾åˆ°ä¿¡æ¯ï¼š1) ä¿¡æ¯æºé€‰æ‹© 2) é—®é¢˜è¡¨è¿° 3) çŸ¥è¯†è¦†ç›–èŒƒå›´",
                status="pending",
                priority=10
            )
        else:
            self.add_todo(
                task_id="deep-understanding",
                description=f"æ·±åº¦ç†è§£é—®é¢˜æœ¬è´¨ï¼Œç»“åˆ {event_count} ä¸ªäº‹é¡¹è¿›è¡Œå¤šç»´åˆ†æ",
                status="pending",
                priority=10
            )

            self.add_todo(
                task_id="cross-reference",
                description="äº¤å‰éªŒè¯ä¿¡æ¯ï¼šå¯¹æ¯”ä¸åŒäº‹é¡¹çš„è§‚ç‚¹ï¼Œè¯†åˆ«å…±è¯†å’Œåˆ†æ­§ç‚¹",
                status="pending",
                priority=9
            )

            self.add_todo(
                task_id="build-narrative",
                description="æ„å»ºå®Œæ•´å™äº‹ï¼šèƒŒæ™¯ä»‹ç» â†’ ç°çŠ¶åˆ†æ â†’ æ·±å…¥æ¢è®¨ â†’ æ€»ç»“ç»“è®º",
                status="pending",
                priority=8
            )

            self.add_todo(
                task_id="cite-sources",
                description="å‡†ç¡®å¼•ç”¨æ¥æºï¼šæ¯ä¸ªå…³é”®è®ºç‚¹éƒ½æ ‡æ³¨äº‹é¡¹åºå· [#1][#2]",
                status="pending",
                priority=7
            )

            self.add_todo(
                task_id="add-insights",
                description="æ·»åŠ æ·±åº¦æ´å¯Ÿï¼šåŸºäºäº‹é¡¹æ€»ç»“è§„å¾‹ã€è¶‹åŠ¿ã€æ½œåœ¨å½±å“å’Œå»ºè®®",
                status="pending",
                priority=6
            )

            if evaluation.get("confidence", 0) < 0.8:
                self.add_todo(
                    task_id="acknowledge-limits",
                    description="è¯šå®è¯´æ˜ï¼šå½“å‰ä¿¡æ¯çš„å±€é™æ€§ï¼Œå“ªäº›æ–¹é¢å¯èƒ½éœ€è¦æ›´å¤šæ•°æ®",
                    status="pending",
                    priority=5
                )

    # ============ å·¥å…·æ–¹æ³• ============

    def _deduplicate_events(self, events: List) -> List:
        """å»é‡äº‹é¡¹ï¼ˆåŸºäºIDï¼‰"""
        seen_ids = set()
        unique = []
        for e in events:
            event_id = e.id if hasattr(e, 'id') else str(e)
            if event_id not in seen_ids:
                seen_ids.add(event_id)
                unique.append(e)
        return unique
